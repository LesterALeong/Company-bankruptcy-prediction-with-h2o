{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepration for Gradient Boosting\n",
    "XGBoost is a popular implementation of Gradient Boosting because of its speed and performance.\n",
    "Internally, XGBoost models represent all problems as a regression predictive modeling problem\n",
    "that only takes numerical values as input. If your data is in a di\u000b",
    "erent form, it must be prepared\n",
    "into the expected format. In this tutorial you will discover how to prepare your data for using\n",
    "with gradient boosting with the XGBoost library in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('bankruptcy_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 65)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing how big the dataset is\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.031545</td>\n",
       "      <td>-0.091313</td>\n",
       "      <td>-0.040269</td>\n",
       "      <td>-0.013529</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-0.016047</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>0.641242</td>\n",
       "      <td>-0.748385</td>\n",
       "      <td>0.126789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>-0.014143</td>\n",
       "      <td>-0.020924</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>-0.214478</td>\n",
       "      <td>-0.013915</td>\n",
       "      <td>-0.173939</td>\n",
       "      <td>-0.046788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.231729</td>\n",
       "      <td>-0.049448</td>\n",
       "      <td>0.304381</td>\n",
       "      <td>-0.080975</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>-0.016047</td>\n",
       "      <td>-0.034963</td>\n",
       "      <td>0.074710</td>\n",
       "      <td>0.469815</td>\n",
       "      <td>0.073759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>-0.008385</td>\n",
       "      <td>-0.008666</td>\n",
       "      <td>-0.023095</td>\n",
       "      <td>-0.033498</td>\n",
       "      <td>-0.205796</td>\n",
       "      <td>-0.015174</td>\n",
       "      <td>-0.073056</td>\n",
       "      <td>-0.027236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058602</td>\n",
       "      <td>0.065060</td>\n",
       "      <td>-0.488404</td>\n",
       "      <td>-0.189489</td>\n",
       "      <td>0.006572</td>\n",
       "      <td>-0.016047</td>\n",
       "      <td>-0.004954</td>\n",
       "      <td>-0.456287</td>\n",
       "      <td>0.270351</td>\n",
       "      <td>-0.071287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010819</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>-0.009437</td>\n",
       "      <td>-0.007919</td>\n",
       "      <td>-0.043455</td>\n",
       "      <td>0.019740</td>\n",
       "      <td>-0.011736</td>\n",
       "      <td>-0.291624</td>\n",
       "      <td>-0.033580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.069376</td>\n",
       "      <td>0.044641</td>\n",
       "      <td>-0.181684</td>\n",
       "      <td>-0.140032</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>-0.010915</td>\n",
       "      <td>-0.005599</td>\n",
       "      <td>-0.462971</td>\n",
       "      <td>-0.286746</td>\n",
       "      <td>-0.085266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010683</td>\n",
       "      <td>0.005384</td>\n",
       "      <td>-0.010840</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>-0.042828</td>\n",
       "      <td>-0.350519</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>-0.554685</td>\n",
       "      <td>-0.046823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.236424</td>\n",
       "      <td>-0.051912</td>\n",
       "      <td>0.678337</td>\n",
       "      <td>-0.014680</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>-0.016047</td>\n",
       "      <td>0.057418</td>\n",
       "      <td>0.097183</td>\n",
       "      <td>0.423405</td>\n",
       "      <td>0.076880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.025295</td>\n",
       "      <td>-0.011056</td>\n",
       "      <td>-0.022535</td>\n",
       "      <td>-0.035892</td>\n",
       "      <td>-0.181557</td>\n",
       "      <td>-0.015623</td>\n",
       "      <td>-0.027841</td>\n",
       "      <td>-0.023694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attr1     Attr2     Attr3     Attr4     Attr5     Attr6     Attr7  \\\n",
       "0 -0.031545 -0.091313 -0.040269 -0.013529  0.007406 -0.016047 -0.000264   \n",
       "1 -0.231729 -0.049448  0.304381 -0.080975  0.007515 -0.016047 -0.034963   \n",
       "2 -0.058602  0.065060 -0.488404 -0.189489  0.006572 -0.016047 -0.004954   \n",
       "3 -0.069376  0.044641 -0.181684 -0.140032  0.007477 -0.010915 -0.005599   \n",
       "4  0.236424 -0.051912  0.678337 -0.014680  0.007879 -0.016047  0.057418   \n",
       "\n",
       "      Attr8     Attr9    Attr10  ...      Attr56    Attr57    Attr58  \\\n",
       "0  0.641242 -0.748385  0.126789  ...    0.014367  0.005457 -0.014143   \n",
       "1  0.074710  0.469815  0.073759  ...    0.008492 -0.008385 -0.008666   \n",
       "2 -0.456287  0.270351 -0.071287  ...    0.010819  0.006779 -0.009437   \n",
       "3 -0.462971 -0.286746 -0.085266  ...    0.010683  0.005384 -0.010840   \n",
       "4  0.097183  0.423405  0.076880  ...    0.010970  0.025295 -0.011056   \n",
       "\n",
       "     Attr59    Attr60    Attr61    Attr62    Attr63    Attr64  class  \n",
       "0 -0.020924  0.068399 -0.214478 -0.013915 -0.173939 -0.046788      0  \n",
       "1 -0.023095 -0.033498 -0.205796 -0.015174 -0.073056 -0.027236      0  \n",
       "2 -0.007919 -0.043455  0.019740 -0.011736 -0.291624 -0.033580      0  \n",
       "3  0.001381 -0.042828 -0.350519  0.002969 -0.554685 -0.046823      0  \n",
       "4 -0.022535 -0.035892 -0.181557 -0.015623 -0.027841 -0.023694      0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glancing at what some of the values are\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'class':'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For features in h2o model\n",
    "cont_names = data.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up desired output and features for logistic regression and xgboost models\n",
    "output = data[data.columns[-1]]\n",
    "features = data[data.columns[:(data.shape[1]-1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9797\n",
       "1     203\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the balance of outputs\n",
    "output.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits data into X (features) and y (predictions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, output, test_size=0.2, random_state=42)\n",
    "train = pd.concat([X_train, y_train], 1)\n",
    "test = pd.concat([X_test, y_test], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lester\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdeZyN5fvA8c9lS9nCtBAiu0FCqCj5JimpJEJ2ql+2FkWlQpSoqCippJKUFkQLSqmQrZGtkHUsJVnHNsP1++N+5jjGzJljzDlnluv9ep3XzLOe65w589znuZfrFlXFGGOMSUmOSAdgjDEmY7OCwhhjTEBWUBhjjAnICgpjjDEBWUFhjDEmICsojDHGBGQFRTYkIu1EZFYaj10lIg3TOaQMT0S+FpGOkY7DmEiwgiKDE5FNInJDep5TVT9U1RuDeO4JIjIkybHRqvrDmTyfiJQWERWRg95jk4j0P8OwI0pVm6rqe5GOI5GI5Pfex7Z+6wqIyBYRaem3rraIzBCRPSKyV0RWi8hQESnsbe8kIsf9/jYbROT/Qhx7QxGJTWWfCSJyzIvpPxGZLSKVkuxTQkQ+FJHdIhInIotEpFmSfUREeovISm+fWBGZIiLVQvHasiorKEw4na+q+YGWwFMi0ji9n0BEcqX3OTMiVT0I3Au8IiIXeKuHA0tU9VMAEbka+AH4BaikqucDNwEJwOV+p1ugqvn9/jbDReSK8LySgIZ7MV0CbAPeSdwgIkWAn4FjQDQQBYwEJvkXlMArQB+gN1AEqABMBW4JxwvIMlTVHhn4AWwCbkhhW3dgPfAfMB0o7rftRuBPYB/wOvAj0M3b1gn42ftdcP9g/3j7/g5UxV2E4nH/iAeBL5PGA+QEngD+Ag4AS4GSycRZGlAgl9+6RcCjfsvFgc+AXcBGoLfftnOB94A9wBrgMSA2yXvUz4v9KJArlfPVAZYA+4G/gZe99XmBicBuYC+wGLjI2/aD3/uXAxgAbPbet/eBQklea0dgC/Av8GQKf796wE4gp9+6O4Dfz+DzMQH4CGjoxV3Mb9vPwGupHO/7LCT527T1W24OrPLekx+Ayn7bKnvr9nr7NPfbdjOw2vtsbAP6AvmAw8AJ73N1EL/PbZLXNSTJueL8lp8FVgI5khzXz/u7CFAeOA7UifT/cWZ/RDwAe6TyB0qhoAAaeRehmsA5wGvAPG9blHcRbOFdNPvgLvrJFRRNcBf4871/rsqJF5uk/6xJ4wEeBVYAFb1jLweKJhNr4sUzl7dcDzgE3OEt5/BieBrIA1wGbACaeNuH4Qq6wkAJXIGQtKCIAUriCpXUzrcAaO/9nh+o5/1+H/AlcB6uEKwFFPS2/eD3/nXBFdCXecd/DnyQ5LW+5cVyOa7wqpzC3/cvoLHf8hSg/xl8PgoDO7zPQme/9flwF8mGqRzv+yx4y1fiLvoVvOUKQBzQGMiNK6TXe+9rbu/3J7zlRrhCoaJ37A6ggV+cNb3fG/r//VKIawLeZ897LR8Ay/22LwQGJXNcGe/9rwjcD2yO9P9wVnhY1VPm1Q4Yr6rLVPUo8DhwlYiUxn37WqWqn6tqAvAq7ptrcuKBAkAlQFR1jaruCDKGbsAAVf1TneWqujvA/v+KyGHchfp1XBUAuIvTBao6WFWPqeoG3IX2bm97K+A5Vd2jqrHe60nqVVXdqqqHgzhfPFBORKJU9aCqLvRbXxQop6rHVXWpqu5P5rna4e5CNqirAnocuDtJtdcgVT2sqsuB5Zxa1ePvI6ANuDYG3N/uoxT2PY2q7sF9kz8PV2AlKowrMH1/dxEZ7rVTxInIAL9963nrD+LuJj4A1nnbWgMzVXW2qsYDL+IKwKtxBX5+YJj3Pn8PzEh8Pbj3s4qIFPT+dsuCfV2eviKyF1f41Afa+22LwhVESe3w2140hX3MGbKCIvMqjrvFBnx11rtx9bnFga1+2xRItvHQ++ceDYwB/haRcSJSMMgYSuK+EQcrCndh6Yv7VpnbW38pUNy7WO31Lg5PABd52095PUl+T25daufrivum/IeILPZrAP0A+BaYLCLbvQtrbk53ynvv/Z7L7/xwasF8yHvdyZkEtBCRc3B3gMtUdXMK+55GRO7B3cXMAV7w27QHV71TLHGFqj6mrp3iCy/eRAtVNbH96GJcnf9z3rakn7MTuPfa9znz1iXa7G0DuBNX8G0WkR9F5KpgX5fnRS/e0rjqqop+2/71f21+ivlt353CPuYMWUGReW3HXRABEJF8uG9Q23Dfokr4bRP/5aRU9VVVrYW7QFTAVSmBu4UPZCtQ9kyC9r6pvwQcAR7wO89G72KV+Cigqjd72095PbgC6rRTJ4krxfOp6jpVbQNciLu4fioi+VQ1XlUHqWoV3DfmZkCHZJ7rlPceKIVrIP77DN4KvFhW4y6uTYG2uIIjKCJyIa59qTuu2qyViFzrnTcO+BVX+JxJPH/j2nZu9VYl/ZwJ7v3f5m0rKSL+15FS3jZUdbGq3oZ7n6cCnyQ+zRnGtAVXffqKiJzrrZ4D3JnkucHdfW4F1gLfASVEpPaZPJ85nRUUmUNuEcnr98iFu6B0FpEa3rfR54BfVXUTMBOoJiK3e/v2wH1TPI2IXCkidb1vznG4C/hxb/PfuHr4lLwNPCsi5b1uiNVFpGiQr2kY8JiI5MVVd+wXkX4icq6I5BSRqiJypbfvJ8DjIlJYRC4BeqZy7oDnE5F7ROQC75vwXu+Y4yJyvYhUE5GcuDaeeL/3wt9HwEMiUkZE8uPe+4+9ar60mITrlXMtro0iWKOBqao616sufAx4y/s84C13EZH+XqGCiJTA1eMny/v73YGrzgL33t8iIv/zPiOP4Npc5uMKojjc3zG3uPE1t+LuyPKIG69TyKuy2s+pn6uiIlIo2BeqqrNxBdO93qqRQEHgHRG52Pu/aAM8ieskoaq6DlfF+ZG4Lrl5vP3ulkzWPTviIt1IYo/AD1xDrSZ5JDby3Y+r+vkPVzdcwu+4m3DfqhJ7Pfk34HbiZGP2/3CNwwdxt+sfAvm9beVxjcR7cRekxHj8ez0NwPUqOoDrJVQimddQmtN7PQnuYtTLWy6OuwDvxFWbLPR7nsTGzL24Xk8DgL+SvEc3JHnOQOebiOutdNCL4XZvfRtcT7E43MXsVU42wP/Aqb2ensZ9c93lna9wgNfqOzaFv3EpXDXRzCTr2+HampI75nbchfP8JOu/A4b6LdcFvvLeu724nkJD8TodeJ+F45zsgfSP975d6HeOO3C9l/bhOhVE+22L9tbt8/ZJ7KCQB/jGe+/3e5+N+n7Hjedk77JUez1561rj7lbO8XvfPsJ9/uO857gtyTGCuxtZhasC3AZ87P8a7JH6Q7w302Rh3u15LNBOVedGOp6zJW5A2N2qel2kYzEmO7CqpyxKRJqIyPleNcQTuG9WC1M5LEMSkWIico2I5BCRirjqjy8iHZcx2UW2GMWaTV2Fq/vOg6sSuF1d19HMKA/wJq5ufS8wGVedZowJA6t6MsYYE5BVPRljjAko01U9RUVFaenSpSMdhjHGZCpLly79V1UvSH3P02W6gqJ06dIsWbIk0mEYY0ymIiJBj/hPyqqejDHGBGQFhTHGmICsoDDGGBOQFRTGGGMCsoLCGGNMQFZQGGOMCShkBYWIjBeRf0RkZQrbRUReFZH1IvK7iNQMVSzGGGPSLpR3FBNwqa5T0hSXxro8Lsf8GyGMxRhjTBqFbMCdqs7z5m9OyW3A++qSTS30Mp0W0+DnazYmzSb9uoVpMdsiHUZI/O/QV1xzONNnkzfpQZUCq/+j4OpAU9mnLpJtFJdw6jzHsZyca/cUInKviCwRkSW7du0KS3Ama5sWs43VO/ZHOoyQuObwXErHb4h0GCbCcu85QqkP1lBq0h/k3Rl3VueKZAoPSWZdsqlsVXUcMA6gdu3alu7WpIsqxQry8X1XRTqM9PduIeAKojvPjHQkJlJUoXZtiD0GL71E3t69IXfuNJ8ukgVFLG6S9kQlcFM7GmOMSYv586FaNShQAN5+G6KioGTJ1I9LRSSrnqYDHbzeT/WAfdY+YYwxabB7N3TvDtdcAy+95NZdcUW6FBIQwjsKEfkIaAhEiUgs8AyQG0BVx+ImfL8ZWI+b9LxzqGIxmV96Nz6v3rGfKsUKptv5QmLJu7Di0zM/bucKuLha+sdjMh5VeP996NsX9uyBRx91j3QWyl5PbVLZrkCPUD2/yVoSG5/T6+JepVhBbquRbN+JjGPFp2m76F9cDaq1DE1MJmPp1w9GjICrr4axY121UwhkuvkoTPaVZRufA7m4GlijtPF3+DDExbn2h65doXx59zNH6FoSLIWHMcZkFt98A1Wrwn33ueWKFV3bRAgLCbCCwhhjMr7t26FVK2ja1HVz7dkzrE9vVU/GGJORffcd3HEHHDsGzz7rGqvPOSesIVhBYdIkXCkwEtNR9D12nPPy5PQGk2UT1nspe4uPd3cPl18ON98MQ4ZAuXIRCcWqnkyahCsFRmI6ivPy5CQqf3i/RUWc9V7Knvbvhz59oEEDOH7cNVpPnhyxQgLsjsKchbD0QrJ0FCa7UIVPP3WFxM6d8MADcPQonHdepCOzgsIYYyJu1y7o2BG+/tqNqJ42Da68MtJR+VjVkzHGRFrBgvDvvzBqFCxalKEKCbA7CpOcAKkj/j5whH8PHg1f47I16Jqsat48GDoUPvsM8ueHhQtDPh4irTJmVCayElNHJOPfg0c55BUSYWlctgZdk9X8+y907gzXXQdr18KmTW59Bi0kwO4oTEpSSB0x+M0FANkvlYYxZ0sV3n3XjYPYvx8efxwGDMgQjdWpsYLCGGPCZeJEqFLFJfCLjo50NEHLuPc6xhiT2R065O4aYmNBxLVH/PhjpiokwAoKY4wJja++cgXC0KHw5ZduXeHCGbotIiVW9ZSRpXXimrPl19MoaaqOTDHhjzGRFBsLDz7o7h4qV3Z3ENdeG+mozkrmK9qykwC9j0LKr6dR0lQdmWLCH2MiaehQmDkTnnsOYmIyfSEBdkeR8WWAiWuy5YRBxpyJRYvg3HPdDHNDhrieTZddFumo0k3AOwoRuVJEXhGRZSKyQ0Q2iMh0EblPRAqEK0hjjMmQ9u2DHj2gXj148km3rmjRLFVIQICCQkRmAD2BH4HbgTJATWAIcD4wU0SahSNIY4zJUFRdRtdKlVxX1169XNfXLCpQ1VNXVf07ybojwCLv8YKIXBiyyLKqM2mgDlP6ikBzS1jjtTHJmDgROnSA2rVhxgyoVSvSEYVUincU/oWEiJQQkeu9388RkXzePv+EPsQs5kwaqMOUviLQ3BLWeG2M5+hRWLPG/d6qFYwf7/IzZfFCAoJozBaRLrgqqEJAWeBS4HXghtCGloVlgAbqpKzB2pgA5s6F//s/N4Bu3To3FWnnzpGOKmyC6R7bG6gH7AdQ1bWAVTkZY7K+f/5xVUyNGrmpSceNC/t81RlBMN1jj6jqMREBQERyAhLSqIwxJtLWr4c6deDgQdej6cknXRfYbCiYguIXEXkMyOu1U/QAZoQ2rCzGvwE7g82vMOnXLfy68T/qlikS6VCMyRj273cTCZUtC127QpcuboR1NhZM1dNjwAHgD6AP8B3wRCiDynL8G7Az2PwKib2drMHaZHtxcdCvH5QufTKJ34gR2b6QgODuKP5PVUcDbySuEJGewOiQRZUVZcAG7ER1yxShbd1SkQ7DmMj58kvo2RO2bHF3EZlgjohwCuaOoksy67qmdyDGGBN2CQnQogU0bw4FCsBPP8Hbb0MRq4r1l+IdhYi0Bu4GyojI536bCgB7Qx2YMcaEjKqrWsqVC4oVg2HD4KGHIE+eSEeWIQWqeloE7AZKAGP81h8AfgtlUMYYEzILF7r8TG+9BTVrwpgxqR+TzaVYUKjqRmAjMCd84WRwaZ0fIoI9nQKl5wBL0WGykT174Ikn4M03oXhxt2yCkmobhZdBdqGI7BORIyJyVESSz/dw+rE3icifIrJeRPons72UiMwVkd9E5HcRuTktLyJs0jo/RAR7OgVKzwGWosNkEx9/7BL4jRvnJhVaswb+979IR5VpBNPr6XXgHmAyUAfoBJRM7SBvYN4YoDEQCywWkemqutpvtwHAJ6r6hohUAb4CSp/JCwi7DNx7KSWWnsNke3/84bq9fvMNXHFFpKPJdILp9ZRDVf8EcqlqvKq+RXB5nuoA61V1g6oewxU0tyXZR4HEeo9CwPYg4zbGmJQdOQKDBp2cq/qJJ2D+fCsk0iiYgiJORPIAy0XkORHpBeQP4rhLgK1+y7HeOn8DgXtEJBZ3N9EruROJyL0iskREluzatSuIpzbGZFtz5kD16jBwoJuvGiB3bsiZM6JhZWbBVD11whUoPYFHgPJAMBXuyeWD0iTLbYAJqvqSiFwFfCAiVVX1xCkHqY4DxgHUrl076TmyjdQappNjjdUm2/j7b3j4YZg0CcqVg1mzoHHjSEeVJaR6R+FVHR1R1b2q+pSq9gYKB3HuWE5tyyjB6VVLXYFPvOdZAOQFooKKPBtKrWE6OdZYbbKN2bPh00/h6adhxQorJNJRoAF3OYA7cdVF36rqGhG5CZfnqTCQWn/PxUB5ESkDbMMN3mubZJ8twP+ACSJSGVdQWN1SANYwbYyf5cvd/BAtW0K7dnDNNVCmTKSjynIC3VG8jcsUewnwhoi8BbwGvKqqqQ4KUNUEXHXVt8AaXO+mVSIyWESae7s9AnQXkeXAR0AnVc22VUvGmCAdPAiPPOJml+vf36XiELFCIkQCtVHUBaqr6nERORf4FyinqjuCPbmqfoVrpPZf97Tf76uBa84sZGNMtjZ1KvTq5TK83nsvPP+8S8VhQibQu3tUVY8DqOphEfnzTAoJY4xJdytWwB13QLVqbhDd1VdHOqJsIVBBUUlElnm/C1DRWxZAVbVmyKPLCMI06VAwPZqsB5PJluLjXVbXRo1cATFzpmuozp070pFlG4EKiowzDVskJabtuLhaSFNxJPZoClQQWA8mk+3Mnw/33w+rVsGff7purzdn7Ew/WVGgpIB/hTOQDC1MaTusR5Mxnv/+c43Ub70FJUvC55+7QsJEhLUAGWMyliNHoEYN2L7d9WwaOBDyB5MMwoSKFRTGmIwhNhZKlIC8eeHZZ11hcfnlkY7KEGRB4eV6KqWq60McT/ilNsdEOjZgB2qwtoZqk20dPuy6uL7wghtZfeut0LFjpKMyfoKZj+IWYAUw21uuISJfhDqwsEltjol0bMAOlILDGqpNtjRrluvJ9Oyz0KoV1KkT6YhMMoK5oxiMG3w3F0BVY0Qka7UqhXGOCWuwNsbTqxeMHg3ly7uMrzaRUIYVTEERr6p7RU5JBmtpNowxZ+74cfczZ06oVw+ioqBfP9cuYTKsYOajWCMirYAcIlJGREYBC0MclzEmq1m2DK66Cl5/3S23awfPPGOFRCYQTEHRE6gFnAA+B44AD4YyKGNMFnLgADz0EFx5JWzZAsWKRToic4aCqXq6TFX7Af1CHUzYhCkth79Jv27h143/UbdMkZA/lzEZxqxZ0KWLGxNx//3w3HNw/vmRjsqcoWDuKF4XkVUi8oyIVAp5ROHg39MphGk5/CV2i7WeTSZbyZMHLrwQFixwVU5WSGRKqd5RqGoDEbkEaA28542p+FhVh4U8ulAKY0+nRHXLFKFt3VJhfU5jwio+Hl5+Gfbvh6FDoWFDWLIEcgTzndRkVEH99VR1m6q+jJs/ewXwbCiDMsZkQj//DFdc4XI0rVsHJ0649VZIZHrBDLgrLyIDRCQGeAs3xal9LTbGOLt3Q7du0KCBa7j+8kv45BMrILKQYBqzJwGTgeaquiXE8YROBBqwE1lDtsnSdu+GyZPhscfg6achX75IR2TSWTBtFFeGI5CQC9O8EsmxhmyT5axZ4+4annkGKlRw3V6L2BehrCrFgkJEPlLVNiLyG6eOxM68M9xFoAE7kTVkmyzh0CHXSD1ihEv93bWry/hqhUSWFuiO4lHvZ/i+ehtjMq5vvoEHHoCNG1121xEj4IILIh2VCYMUW5tUNdb7tauq/uX/ALqGJzxjTIZw8CC0b+/GRcydCxMmWCGRjQTTLeGmZNbdkt6BGGMymOPHYeJE9zN/fpfhdflyNzbCZCuB2ijuA+4HKojIMr9NBYCloQ4sK0icqMgmJTKZztKlcN997ue558Kdd9psc9lYoDaKT4DvgOeB/n7rD6jqPyGNKovwLySsx5PJFPbtg6eegjFjXOqNyZOhRYtIR2UiLFBBcUxV14vIae0RIlJQVZOfqs2cwiYqMpnKnXfC999Djx4wZAgUKhTpiEwGEKig+BRoCqzCdY/1n7lIsdHZxmQNGza4hukCBVzX1xw5XEpwYzyBej019X6WVNVS3s/EhxUSxmR2x465tN/R0e7uAaBuXSskzGlSHZktIvWA31X1kIi0Aa4AXvXrPpvx+KfrSBTmtB3GZGjz5rn5IdasgZYtoXfvSEdkMrBguseOAw6LSHXgCeBv4MOQRnW2/OebSBTmtB3GZFgjR8J118HhwzBzJkyZApdYZwuTsmCSAiaoqorIbcArqvq2iLQLdWBnLYLpOozJcE6cgLg41w5xyy2waxcMGADnnRfpyEwmEMwdRZyIPAq0B2aKSA4gd2jDMsakm1Wr3B1Ep05uuUIF1zZhhYQJUjAFRWtcj6f7VHUHUAJ4OZiTi8hNIvKniKwXkf4p7NNKRFZ7061OCjpyY0xghw7B449DjRquLaJZM1BN/Thjkggmzfh2ERkP1BaRm4AlqvpuaseJSE5gDNAYiAUWi8h0VV3tt0954HHgGlXdIyIXpvWFACcbsSMw30RiKnF/NiLbRMxvv7mBcps2QefOMHw4REVFOiqTSQUzw92dwDJc1VMHYImI3BHEuesA61V1g6oew01+dFuSfboDY1R1D8BZj/j2LyTCPN/E6h2njz+0Edkm7BLvGEqVco8ff4Tx462QMGclmMbsp4ErVfVvABG5CJgFfJHKcZcAW/2WY4G6Sfap4J3zFyAnMFBVvwkippRFqBHbRmCbiEpIgNGjYfp0mD0bihZ1hYQx6SCYNoociYWEZ1eQx0ky65JWkOYCygMNgTbA2yJy/mknErlXRJaIyJJdu3YF8dTGZCOLFkGdOvDQQ5A3L+y37DomfQVzwZ8tIl+JyD0icg8wHfg2iONigZJ+yyWA7cnsM01V41V1I/AnruA4haqOU9Xaqlr7AsuBb4xz8KDLyVSvHvz9txsPMXMmFC4c6chMFhNMQfEIMAHX5lAXeI+Ts98FshgoLyJlRCQPcDeukPE3FbgeQESicFVRG4KK3JjsLndu+OEH6NXr5AhrSe5G3pizE7CNQkSaAeWAFap6RmP8VTVBRHri7j5yAuNVdZWIDMb1nEq8M7lRRFYDx4FHVXV3Wl4IS96FzT/DpfXTdHhqUurZBNa7yYTR+vUweLBLA16ggJsvIm/eSEdlsrgU7yhE5DXcPBSXAMNF5IkzPbmqfqWqFVS1rKoO9dY97RUSqPOwqlZR1WqqOjmNr+NkbqcQ9XZKqWcTWO8mEwZHj8Kzz0LVqjB1KsTEuPVWSJgwCHRHcT1Qw7szyAf8CDwXnrDS6NL6ULtzyE5vPZtMRMydC//3f/Dnn9C6Nbz8MhQvHumoTDaS2sRFCQCqGuel7jDGhJOqmyMiPh6++QaaNIl0RCYbClRQVPKbK1uAit6y4GqNaoY8OmOyoxMn4J134KaboGRJ+OADOP98N3e1MREQqKDIHJM3RChthzEh8fvvbp6IBQvg6adh0CAoVizSUZlsLsWCQlX/CmcgaRahtB3GpKuDB12hMHKkGwcxYQJ06BDpqIwBgkvhkfHZ3BMmsxs4EF56Cbp1g2HDXAoOYzKIrFFQGJMZbd3qJhOqVAn694fbb4f6oRkHZMzZCKonk4jkEZFyoQ7GmGwhIcF1ca1cGe67z62LirJCwmRYwaQZvwVYAcz2lmuISGqZY40xyVm4EGrXhkcegYYN4b33Ih2RMakK5o5iMC7H014AVY3BpfWIvMS0HSE06dcttH5zQYqjso0J2syZcPXV8O+/8Pnn8OWXULp0pKMyJlXBFBTxqro3ybqMMZ9iiNN2wMnUHZamw6SJKmzzcoTdcIPL07RmDdxxhyXwM5lGMI3Za0SkFZBDRMoAfYCFoQ3rDIQ4bQdY6g6TRmvXwgMPuJ+rV0P+/DBgQKSjMuaMBXNH0ROoBZzAzWp3FHgwlEEZk6kdOeK6u1arBkuWwOOP26hqk6mlekehqnFAP+9hjAlk50649lpYtw7atHG9my6+ONJRGXNWUi0oRGQ2ybRJqOqNIYkoWGGaf8LmmjBBiY93EwlddJErKMaMgcaNIx2VMekimDYK/0rVvMCduOqnyArT/BPWiG0COnECxo2D556D+fOhRAl4++1IR2VMugqm6unXJKt+FJEfQxTPmbH5J0wkLV/uBsz9+is0auTuKozJgoIZcFfQ73G+iPwPsHSWJvtShb59oVYt2LDBpQGfMwfKlIl0ZMaERDBVT6twbRQCJAAbge6hDMqYDE0E9uyBrl1dAr/ChSMdkTEhFbCg8Ga1u0tVM864CWMiYfNm6NPHzRFRsya89RbksEkfTfYQ8JOuqieAUWGKJXghTN1hKTvMKeLjYfhwqFIFZs9281aDFRImWwnm0z5bRG4LeSRnIoQ9nqy3k/GZP9/dPfTr57q6rlnjxkYYk80E00bREygkIkeBw5ycM7tISCNLTQh7PFlvJwO4Bup9+2DqVLgtY31XMiacUryjEJFS3q9RQG4gP3CBt3xB6EMzJsxU4f334euv3XK/fi5HkxUSJpsLVPU0FUBVjyf3CFN8xoTHH3+4sRAdO8K777p155zjEvkZk80FqnrKFjmQE1N1JLKUHdnM4cNuVPULL0C+fPDmm27eamOMT6CC4hIReTWljaraOwTxhF3SfE7WiJ3NfPklDBkC99wDL77ocjUZY04RqKA4DCwNVyCRZI3X2czOnRATAzfdBHfd5WaZq1Mn0lEZk2EFKih2q6pN6GuyjuPHXdXS449DnjywZYubJ8IKCWMCCtSYfSxsURgTasuWwVVXQY8ermCYPzDxVfMAACAASURBVN8mEzImSIHuKO4OdKCICHCJqsamb0jGpLONG13hEBUFkybB3XfbfNXGnIFABcUIL9fTNFxbxS7cfBTlgOuB/wHPAJmuoPDv6WS9nLIoVVixAqpXd1ld330Xbr0Vzj8/0pEZk+mkWPWkqncBTwEVgTHAT7hCoxvwJ9BIVWeHI8j0ltjTCayXU5a0cSM0awZXXAG//+7WtW9vhYQxaRQwhYeqrgaeTOvJReQm4BUgJ/C2qg5LYb+WwBTgSlVdktbnOxPW0ykLOnbMzVE9eLBL2vfiiy6ZnzHmrAST6ylNRCQn7k6kMa56arGITPcKH//9CgC9gaQz6RkTvOPH4eqrYelSaNECRo2CkiUjHZUxWUIocyXXAdar6gZVPQZMBpJLmvMsMBw4EsJYTFa130sHnzMndOniBtB99pkVEsako1AWFJcAW/2WY711PiJyBVBSVWcEOpGI3CsiS0Rkya5du9I/UpP5qMKECXDZZTBtmlv3wAOubcIYk66CmTP7MxG5xesBdSaS63+ofufNAYwEHkntRKo6TlVrq2rtCy6wxLXZ3urV0LAhdO4MlSpB2bKRjsiYLC2Yi/8bQFtgnYgME5FKQZ47FvC//y8BbPdbLgBUBX4QkU1APWC6iNQO8vwmOxo+HC6/HFauhLffhnnzoGrVSEdlTJaWakGhqnNUtR1QE9iEm/Fuvoh0FpHcAQ5dDJQXkTIikgc3gG+633n3qWqUqpZW1dLAQqB5uHo9mUxGvZvRiy+Gdu1cWvCuXW1KUmPCIKj/MhEpCnTCjaH4DdfltSaQ4jgKVU3AzY73LbAG+ERVV4nIYBFpfpZxm+xi+3aXuO+119xyhw6ubcKqII0Jm1S7x4rI50Al4APgVlXd4W36WEQCfvtX1a+Ar5KsezqFfRsGE7DJJo4fh9dfhyefhPh41/XVGBMRwYyjeNu74PuIyDmqelRVw9+ecOhf2LzOzZltsqaYGDd50NKlcOONrsCwBmtjIiaYqqchyaxbkN6BBO3QHvezWsuIhWBCbN8+V+X08cfwzTdWSBgTYSneUYjIxbhxD+d64x0Su7sWBM4LQ2wpu7Q+1O4c0RBMOlKFKVNg3TpX1XTddbBhA+TNG+nIjDEErnpqgmvALgG87Lf+APBECGMy2clff0HPnu7O4cor4bHHIHduKySMyUBSLCi82e3eE5E7VfWzMMZksoOjR13SviFDXMHwyituZHWukKUfM8akUaCqp3tUdSJQWkQeTrpdVV9O5rAMLXEeCpuDIgPYuhWefdbNETFqFFxiqd6NyagCfX3L5/3MH45AwsG/kLA5KCJg1y7XQN2zJ5Qr51JxXHZZpKMyxqQiUNXTm96vr6tqlsnEZ/NQRMCJE26GuccegwMHoHFjqFjRCgljMolgusfOF5FZItJVRAqHPCKTtaxc6XoxdesG0dFujETFipGOyhhzBoLJ9VQeGABEA0tFZIaI3BPyyEzmd+yYGzC3Zg2MHw8//mgzzhmTCQWV60lVF6nqw7jJiP4D3gtpVCZz+/57l4IjTx745BOXwK9zZ5DkMs8bYzK6YOajKCgiHUXka2A+sANXYBhzqthYuPNO+N//4P333br69SEqKrJxGWPOSjCd1pcDU4HBqhq51B0m40pIgNGj4amn3J3E88+7VODGmCwhmILiMlXV1Hcz2Vb79jB5MjRtCmPGQJkykY7IGJOOAg24G6WqD+JmnTutoFBVm1MiO9u7142izp8fevRwVU533mntEMZkQYHuKD7wfr4YjkBMJqHqBs099BDcfTeMHOnaIYwxWVaKjdmqutT7tYaq/uj/AGqEJzyToaxfD02aQJs2UKIE3GO9pI3JDoLpHtsxmXWd0jkOk9FNmgRVq8Kvv7qG64ULoVatSEdljAmDQG0UbYC2QBkRme63qQCwO9SBmQwiPt5ld61dG1q2hOHDoXjxSEdljAmjQG0UiWMmooCX/NYfAH4PZVAmA/jnH3jkEYiLg88/hwoVYOLESEdljImAQEkBNwObAcugl52cOAFvvw39+rlCol8/NzYiZ85IR2aMiZBAVU8/q2p9ETkA+HePFUBVNTITOhw7GJGnzRY2bHAN1AsWQMOG8MYbUKlSpKMyxkRYoDuK+t7PAuELJ0jVWkY6gqypUCE3PuK999wgOhsTYYwhuFxPZUXkHO/3hiLSW0TOD31oKciTH2p3jtjTZznTp0OLFq56qWhRlxa8QwcrJIwxPsF0j/0MOC4i5YB3gDLApJBGZUJvyxa4/Xa47TZYuxZ27HDrcwSVUNgYk40Ec1U4oaoJwB3AKFV9CCgW2rBMyCQkwIsvQuXKMGsWvPAC/PabG0BnjDHJCCYpYLw3pqIjcKu3LnfoQjIhdfy469XUqBG89hqULh3piIwxGVwwdxSdcV1kh6rqRhEpA2S6DvWTft3Crxv/i3QYkbFnj+vmeuAAnHMO/PKLa5uwQsIYE4RU7yhUdTXQ2295IzAslEGFwrSYbQDcVuOSCEcSRqou9cbDD8Pu3XDNNdC8uWu0NsaYIAXT6+kaEZktImtFZIOIbBSRDeEILr3VLVOEtnVLRTqM8Fi7Fho3duMiSpeGJUtcIWGMMWcomDaKd4CHgKXA8dCGY9LNgw+6wuH11+Hee21ktTEmzYIpKPap6tchj8Scvdmz3UjqkiXdqOpzzoGLL450VMaYTC6YgmKuiIwAPgeOJq5U1WWpHSgiNwGvADmBt1V1WJLtDwPdgARgF9DFyzGVJpN+3eJri0hq9Y79VCkWmawjIbdzp2uH+OgjN9vc6NFw6aWRjsoYk0UEU1DU9X7W9lunQKNAB4lITmAM0BiIBRaLyHSvcTzRb0BtVT0kIv8HDAdaBxt8UtNitqVYIFQpVjDrNWSfOAHjxkH//nD4MDzzjPvdGGPSUTC9nq5P47nrAOtVdQOAiEwGbgN8BYWqzvXbfyFw1lOmVSlWkI/vyyYJb59/HgYMcGMiXn8dKlaMdETGmCwomF5PF4nIOyLytbdcRUS6BnHuS4Ctfsux3rqUdAWSbQsRkXtFZImILImPjw/iqbOwAwdg40b3+/33w4cfwpw5VkgYY0ImmAF3E4BvgcRpzdYCDwZxXHJZ5TSZdYjIPbiqrRHJbVfVcapaW1Vr586dTQeFq8IXX0CVKtC6tVsuWhTatrUEfsaYkAqmoIhS1U+AEwBe3qdgusnGAiX9lksA25PuJCI3AE8CzVX1aNLtBti82Y2BaNECihSBV1+1wsEYEzbBNGbHiUhRvLsBEakH7AviuMVAeS/lxzbgbtwc3D4icgXwJnCTqv5zJoH7S+ztlCV7Ni1YADfc4H5/8UXo0wdyBfNnM8aY9BHMFedhYDpQVkR+AS4AUp05SFUTRKQnrtoqJzBeVVeJyGBgiapOx1U15QemiPuGvEVVz3j4sH8hkWV6Nu3fDwULQs2a0KULPPoolMq4o8rj4+OJjY3lyJEjkQ7FmGwtb968lChRgvSsphfVZJsNTt1JJBdQEdfu8KeqRqxFuXbpQrpk06k3NK3fXACQNXo77d7turjOmgWrVkH+/JGOKCgbN26kQIECFC1aFLFqMWMiQlXZvXs3Bw4coEyZMqdsE5Glqlo7hUMDSrGNQkSuFJGLvSdPAGoBQ4GXRKRIWp7MBKAK77/vRla/+65rsM5EF9wjR45YIWFMhIkIRYsWTfc7+0CN2W8Cx7wnvxaXMfZ9XPvEuHSNIrvbt8+NhejYEcqXh2XLYPhwyJcv0pGdESskjIm8UPwfBioocqpq4gQOrYFxqvqZqj4FlEv3SNIoU88zkVjtV7AgREW5UdY//wzVq0c2LmOM8ROwoPDaJgD+B3zvty3DdLvJtPNMfPuta6iOjXVVTFOmQPfuNmf1WcifDu0527dvp2XLlPtq7N27l9dffz3o/ZPq1KkTZcqUoUaNGlx++eV89913ZxVvehs7dizvv//+WZ9n06ZNnHvuudSoUYMqVarQoUMH/AfL/vzzz9SpU4dKlSpRqVIlxo07tZLi/fffp2rVqkRHR1OlShVefPHFZJ9n1KhR6RJvqBw9epTWrVtTrlw56taty6ZNm07b588//6RGjRq+R8GCBRk1ahQAMTEx1KtXjxo1alC7dm0WLVoEwIwZM3jmmWfC90JUNdkHbmzDL8A0XE6mxIbvcsAvKR0X6ketSwuqv1Zj52ursfM109i+XbV1a1VQrVBBdenSSEeULlavXh3pEDRfvnwhf46NGzdqdHR0mo/v2LGjTpkyRVVVv//+ey1Xrly6xBUfH58u50kv/u9TQkKCXn/99Tpx4kRVVd2xY4eWLFlSl3qf/V27dmnNmjV1xowZqqr61Vdf6RVXXKHbtm1TVdXDhw/ruHHjTnuO+Ph4rVat2hm99nC/T2PGjNH77rtPVVU/+ugjbdWqVcD9ExIS9KKLLtJNmzapqmrjxo31q6++UlXVmTNn6nXXXaeqqidOnNAaNWpoXFxcsudJ7v8R19s0TdfdFO8MVHWoiHwHFANmeU8E7i6kV+iKrixszBh44gk4ehQGDXLTk55zTqSjSneDvlzF6u370/WcVYoX5Jlbo8/4uM2bN9OlSxd27drFBRdcwLvvvkupUqX466+/aNeuHcePH6dp06a8/PLLHDx4kE2bNtGsWTNWrlzJqlWr6Ny5M8eOHePEiRN89tlnPPXUU/z111/UqFGDxo0b06NHD9/+x48fp1+/fnz77beICN27d6dXr5T/Va666iq2bTuZ7Xjp0qU8/PDDHDx4kKioKCZMmECxYsVYvHgxXbt2JV++fNSvX5+vv/6alStXMmHCBGbOnMmRI0eIi4vj+++/Z8SIEXzyySccPXqUO+64g0GDBhEXF0erVq2IjY3l+PHjPPXUU7Ru3Zr+/fszffp0cuXKxY033siLL77IwIEDyZ8/P3379iUmJob777+fQ4cOUbZsWcaPH0/hwoVp2LAhdevWZe7cuezdu5d33nmHBg0apPg6c+bMSZ06dXyvdcyYMXTq1ImaNWsCEBUVxfDhwxk4cCC33HILzz//PC+++CLFi7tkEHnz5qV79+6nnff777+nZs2a5PLGFb311luMGzeOY8eOUa5cOT744APOO+88OnXqRJEiRfjtt9+oWbMmgwcPplevXqxYsYKEhAQGDhzIbbfdxqZNm2jfvj1xcXEAjB49mquvvvoMP3GnmjZtGgMHDgSgZcuW9OzZE1VNsR3hu+++o2zZslzqZX8WEfbvd/9L+/bt870nIkLDhg2ZMWMGrVq1OqsYgxGwCklVFyazbm3owsnili6FunVdgVG+fKSjyRZ69uxJhw4d6NixI+PHj6d3795MnTqVPn360KdPH9q0acPYsWOTPXbs2LH06dOHdu3acezYMY4fP86wYcNYuXIlMTExAKdUJYwbN46NGzfy22+/kStXLv77L3Db2TfffMPtt98OuHEovXr1Ytq0aVxwwQV8/PHHPPnkk4wfP57OnTszbtw4rr76avonyQ68YMECfv/9d4oUKcKsWbNYt24dixYtQlVp3rw58+bNY9euXRQvXpyZM2cC7oLz33//8cUXX/DHH38gIuzdu/e0+Dp06MBrr73Gddddx9NPP82gQYN8VSIJCQksWrSIr776ikGDBjFnzpwUX+eRI0f49ddfeeWVVwBYtWoVHTt2PGWf2rVrs2rVKgBWrlxJrVq1Ar53AL/88ssp+7Vo0cJXoAwYMIB33nnHV1CvXbuWOXPmkDNnTp544gkaNWrE+PHj2bt3L3Xq1OGGG27gwgsvZPbs2eTNm5d169bRpk0blixZctrzNmjQgAMHDpy2/sUXX+SGxMGxnm3btlGypEtQkStXLgoVKsTu3buJiopK9jVNnjyZNm3a+JZHjRpFkyZN6Nu3LydOnGD+/PmnvGc//fRT5AsKc5b274enn4b27aFWLZfh9ZxzMlW317RIyzf/UFmwYAGff/45AO3bt+exxx7zrZ86dSoAbdu2pW/fvqcde9VVVzF06FBiY2Np0aIF5VMp3OfMmcP999/v+4ZbpEjyvcgfffRRHnvsMf755x8WLnTfxf78809WrlxJ48aNATh+/DjFihVj7969HDhwwPfNtm3btsyYMcN3rsaNG/ueZ9asWcyaNYsrrrgCgIMHD7Ju3ToaNGhA37596devH82aNaNBgwYkJCSQN29eunXrxi233EKzZs1OiXHfvn3s3buX6667DoCOHTty1113+ba3aNECgFq1aiVb7w747rzWrVtHy5Ytqe510kjpG/WZ9tbZsWMHlStX9i2vXLmSAQMGsHfvXg4ePEiTJk182+666y5yerM8zpo1i+nTp/vaPY4cOcKWLVsoXrw4PXv2JCYmhpw5c7J2bfLfiX/66aegYzxZEXNSSq/z2LFjTJ8+neeff9637o033mDkyJHceeedfPLJJ3Tt2tVXKF944YVs335aVqSQyNQtpxm2x5MqfPopVK7s8jL9+KNbnzdvli8kMrozuRi1bduW6dOnc+6559KkSRO+//77gPsHqlLwN2LECNavX8+QIUN836xVlejoaGJiYoiJiWHFihXMmjUr2QuNv3x+XahVlccff9x3jvXr19O1a1cqVKjA0qVLqVatGo8//jiDBw8mV65cLFq0iDvvvJOpU6dy0003BfGOnHSOV2WaM2dOEhISkt2nbNmyvjgWLlzI9OnTAYiOjj7tm/rSpUupUqWKb/vSpUtTjeHcc889ZbxAp06dGD16NCtWrOCZZ545ZVvS9+mzzz7zvU9btmyhcuXKjBw5kosuuojly5ezZMkSjh07luzzNmjQ4JTG58RHcndVJUqUYOtWl0Q7ISGBffv2pfgF4uuvv6ZmzZpcdNFFvnXvvfeer1C+6667fI3Z4Aq4c889N9X3KT1k6oIiQ/Z42rgRmjWDu+6CCy90uZoefjjSUWVbV199NZMnTwbgww8/pH79+gDUq1ePzz77DMC3PakNGzZw2WWX0bt3b5o3b87vv/9OgQIFkq12ALjxxhsZO3as78IZqOopR44c9OnThxMnTvDtt99SsWJFdu3axYIFLstAfHw8q1atonDhwhQoUMB355FSrABNmjRh/PjxHDx4EHDVHv/88w/bt2/nvPPO45577qFv374sW7aMgwcPsm/fPm6++WZGjRrlq0pLVKhQIQoXLuz79vzBBx/47i7OVLFixRg2bJjvm3KPHj2YMGGC7zl3795Nv379fHd7jz/+OI899hg7d+4EXM+hV1999bTzVq5cmfXr1/uWDxw4QLFixYiPj+fDDz8M+D699tprvkL4t99+A9xdVLFixciRIwcffPABx48nn/v0p59+8hUy/o+k1U4AzZs357333gPg008/pVGjRil+mfjoo49OqXYCKF68OD96XzS///77U+5q165dS9WqVVN8nekp01c91S1ThLZ1M1AOpA8/hHnzYORI6NnTEviF0aFDhyhRooRv+eGHH+bVV1+lS5cujBgxwteYDa7u95577uGll17illtuoVChQqed7+OPP2bixInkzp2biy++mKeffpoiRYpwzTXXULVqVZo2bUqPHj18+3fr1o21a9dSvXp1cufOTffu3enZs2eK8YoIAwYMYPjw4TRp0oRPP/2U3r17s2/fPhISEnjwwQeJjo7mnXfeoXv37uTLl4+GDRsmGyu4gmrNmjVcdZVLZZM/f34mTpzI+vXrefTRR8mRIwe5c+fmjTfe4MCBA9x2220cOXIEVWXkyJGnne+9997zNWZfdtllvvcuLW6//XYGDhzITz/9RIMGDZg4cSLdu3fnwIEDqCoPPvggt956KwA333wzf//9NzfccIPvLq1Lly6nnbNp06a0b9/et/zss89St25dLr30UqpVq5Zigf7UU0/x4IMPUr16dVSV0qVLM2PGDB544AHuvPNOpkyZwvXXX3/KXUhade3alfbt21OuXDmKFCniK+i3b99Ot27d+OqrrwD32Z09ezZvvvnmKce/9dZb9OnTx1dV6N+NeO7cuadUU4VUWrtLRerh3z02w3SNnTdPdfZs9/uRI6pbt0Y2ngjICN1jz0RcXJyeOHFCVV23xebNm0c4opQdOHDA9/vzzz+vvXv3jmA0Gcvtt9+ua9eujXQYYbdz505t1KhRitvD1j3WBOHff+Gxx1xupgYNXDrwc84Bv2+1JmNaunSpr6vi+eefz/jx4yMdUopmzpzJ888/T0JCApdeeikTJkyIdEgZxrBhw9ixY0eqHQ2ymi1btvDSSy+F7fmCyh6bkSRmj5306xae+GIFdcsUCX/WWFWYMMGl/t63Dx55BJ56KtPlZkpPa9asOaUHijEmcpL7fzyb7LGZ9o4iog3ZX33l5oi45hoYOxbC1KBkjDGRkKl7PYW1IfvQIfjlF/f7zTfDtGmu0doKCWNMFpepC4qw+fprVyA0bQp797qxEM2bWwI/Y0y2YFe6QLZtc+Mhbr7ZNVJ/+SWcf36kozLGmLCygiIl//wDVarAjBkwZAgsXw5pHHBkQm/r1q2UKVPGN8htz549lClThs2bNwOwbt06mjVrRtmyZalVqxbXX3898+bNA2DChAlccMEF1KhRg+joaFq2bMmhQ4fSLbaYmBhff/nkLFq0iGuvvZaKFStSqVIlunXrxqFDh5gwYULAcRhn6uabb/bldHr11VepXLky7dq1Y/r06QwbNizN57WU4k4wKcXBpapv2bIllSpVonLlyr5Blk899RTVq1enRo0a3Hjjjb70HGFPKZ6ctParjdQjcRxFyMZQxMae/P2VV1TXr0//58iCMsI4ihdeeEG7d++uqqr33nuvPvfcc6rq0lSXL19ep02b5tt3xYoV+u6776qq6rvvvqs9evTwbWvTpo2OHz8+3eJKen5/O3fu1FKlSun8+e6zfOLECZ0yZYru3Lkz4HFnq2LFirphw4Y0HZs0VbelFHeCTSneoUMHfeutt1RV9ejRo7pnzx5VVd23b59vn1deecV3rtRSiifHxlGEyr59MGAAvPkmLFzoJhXq3TvSUWVOX/eHnSvS95wXV4Omgb/1PvTQQ9SqVYtRo0bx888/89prrwEudcdVV11F8+bNfftWrVo12fQHCQkJxMXFUbhwYSDlNOUprZ8yZQqDBg0iZ86cFCpUiDlz5vD0009z+PBhfv75Zx5//HFat27te74xY8bQsWNH32hqEUl2IqQvv/ySIUOGcOzYMYoWLcqHH37IRRddxI8//kifPn18x86bN4+DBw/SunVr9u/fT0JCAm+88QYNGjSgdOnSLFmyhAEDBrBhwwaaN29Oly5dKFy4MEuWLGH06NHs2rWL+++/ny1btgDuW/w111zDwIED2b59O5s2bSIqKopJkyYl+zewlOIDgZRTiu/fv5958+b5xsLkyZOHPHnyAFCwYEHffnFxcb7jwp1SPDlW9aQKn3ziEviNGQP33w9ly0Y6KpMGuXPnZsSIETz00EOMGjXK9w+4atUq34UqJR9//DE1atTgkksu4b///vOlk0hMU/7777/Trl07entfHlJaP3jwYL799luWL1/O9OnTyZMnD4MHD6Z169bExMScUkhA8Cm169evz8KFC/ntt9+4++67GT58OOBSW48ZM4aYmBh++uknzj33XCZNmkSTJk2IiYlh+fLl1KhR45RzjR07luLFizN37lweeuihU7b16dOHhx56iMWLF/PZZ5/RrVs337alS5cybdq0FAsJOJlSPDHJ4KpVq057femVUnzx4sUsX76cypUr88477/i2JaYUf+mllxg6dCiNGjVi8eLFzJ07l0cffZS4uDhfSvFly5bx8ccf+/5+SZ1JAsCUUor727BhAxdccAGdO3fmiiuuoFu3br7CCuDJJ5+kZMmSfPjhhwwePPiU9+xMstamt+x9R6EKLVrA1KnuDmL6dKidpvEoxl8q3/xD6euvv6ZYsWKnpOxO6o477mDdunVUqFDBl4K8devWjB49GlWlR48ejBgxgv79+wdMU57c+muuuYZOnTrRqlUrX9bP9BAbG0vr1q3ZsWMHx44do0yZMr7ne/jhh2nXrh0tWrSgRIkSXHnllXTp0oX4+Hhuv/320wqKQObMmcPq1at9y/v37/flTGrevHmK2UotpXhwKcUTEhJYtmwZr732GnXr1qVPnz4MGzaMZ599FoChQ4cydOhQnn/+eUaPHs2gQYOA8KYUT072vKNIbGgTgfr1XSrwRYuskMjkYmJimD17NgsXLmTkyJHs2LEDcGmrly1b5tvviy++YMKECclmdxURbr31Vl9Dd3LbA60fO3YsQ4YMYevWrdSoUeO0b5RJBZtSu1evXvTs2ZMVK1bw5ptv+lJo9+/fn7fffpvDhw9Tr149/vjjD6699lrmzZvHJZdcQvv27c+oAfjEiRMsWLDAlxF127ZtFChQACBgkjxLKR5cSvESJUpQokQJ6tatC7gqKv/PZqK2bdv6shtDeFOKJyf7FRQ//ADVq7sBc+DSb/TqBd43EJM5qSr/93//x6hRoyhVqhSPPvqobzKitm3b8ssvv/guXkDAXk0///wzZb3qx5TSlKe0/q+//qJu3boMHjyYqKgotm7dGjA1ec+ePXnvvff49ddffesmTpzoS7GdaN++fVxyictCkJi2OvH5qlWrRr9+/ahduzZ//PEHmzdv5sILL6R79+507do12QtRSm688UZGjx7tW06afjw1llI8cErxiy++mJIlS/Lnn38CburTxEJz3bp1vv2mT59OpUqVfMvhTCmerLS2gkfqkeZeT//8o9qhgyqolimj+t13wR9rUhXpXk9vvvnmKb1MEhIStGbNmvrDDz+oquqaNWu0adOmWqZMGa1Xr542btxYZ3sZf999912NiorSyy+/XKtVq6ZNmzbVv//+W1Vdj57rr79eq1Wrpo0aNdLNmzcHXH/HHXdo1apVNTo6Wnv37q0nTpzQ3bt364N44QAADb9JREFUa+3atfXyyy/XyZMnnxb7/PnztX79+lqhQgWtVKmS3nvvvRoXF3dKr6epU6dqmTJltH79+tq3b1+97rrrVFW1Z8+eGh0drdWrV9e7775bjxw5ohMmTNDo6GitUaOG1q9f39e76dJLL9Vdu3ad9rv/8+zatUtbtWql1apV08qVK/t63jzzzDM6YsSIZN97/15Pqq6XTvXq1XXevHmqqvrjjz9q7dq1tWLFilqhQgV9/fXXTzl+/PjxGh0drVWqVNHo6Gh96aWXTnuOTZs2aYMGDXzLr7/+upYuXVqvu+467dmzp3bs2FFVVTt27KhTpkzx7Xfo0CG99957fX+TW265RVVV165dq9WqVdO6detq//79NV++fMm+tjNx+PBhbdmypZYtW1avvPJK/euvv1RVddu2bdq0aVPffr/99pvWqlVLq1Wrprfddpv+999/qqraokULjY6O1mrVqmmzZs001q8H5i233KK///570LGkd6+nTJsUsPWbru9xUAkBP/oIevSAgwddIr8nn4TzzgtxpNmLJQU0oXbHHXcwfPjwbJcp9u+//6Zt27Z89913QR+T3kkBs0fVU0KCS8EREwNDh1ohYUwmlJhSPLsJd0rx5GTNXk9xcfDss1CqFDzwANxzj3vYfNXGZFoVK1akYsWKkQ4j7K688spIh5D57ijiTyit31zA6h37k99hxgyIjoYXXoDELm8iVkiEQWarxjQmKwrF/2GmKygSjp9g9Y79VClW8NS5KGJj3ZiIW291EwjNmwejRkUu0Gwmb9687N692woLYyJIVdm9ezd58+ZN1/NmyqqnKsUKnt6IvWEDfPstPP88PPwweKNyTXiUKFGC2NhYdu3aFelQjMnW8ubNS4l0no45UxYUPosWwYIF0KcPXHstbNkCRYtGOqpsKXfu3L7RwsaYrCWkVU8icpOI/Cki60WkfzLbzxGRj73tv4pI6WDOe96hA66Rul49ePll13gNVkgYY0wIhKygEJGcwBigKVAFaCMiVZLs1hXYo6rlgJHAC6mdN+fhBEYObOOyvPbuDStWuDYJY4wxIRHKO4o6wHpV3aCqx4DJwG1J9rkNSMxH8CnwP0klW1iePUfZXfhCWLzYNVb7peY1xhiT/kLZRnEJsNVvORaom9I+qpogIvuAosC//juJyL3Avd7i0XKb/1hJEKmJs4EokrxX2Zi9FyfZe3GSvRcnpXkQSigLiuTuDJL2nQxmH1R1HDAOQESWpHUYelZj78VJ9l6cZO/FSfZenCQiS1LfK3mhrHqKBUr6LZcAkiZU9+0jIrmAQv/f3rkHW1XVcfzzlVCGh8CEOehomIiFSIg0+VaKYYocdEYDSwPMsdLxEWWORU6UTqMxlRnqVUlJ84GPkW6KEaMQjgqicu8F8TFaZIaJMmaa1oT9+mP9jndzOPecfS+cxz38PjN7ztprr732b//2OXvt9VtnfxewvfZzEARBUDeq2VCsAQ6SdICk3YHTgNaiMq3ATE+fCjxs8cZWEARBQ1G10JOPOZwHLAX6ADeZ2TOSfkSSu20FfgXcKulFUk/itBxV31Atm3sh4YtOwhedhC86CV900mNf9DqZ8SAIgqC29DqtpyAIgqC2REMRBEEQlKVhG4pqyX/0RnL44luSNkjqkPSQpI/Ww85aUMkXmXKnSjJJTfvXyDy+kDTNvxvPSLq91jbWihy/kf0lLZe01n8nU+phZ7WRdJOkzZLWd7Fdkq52P3VIGp+r4p7OoVrNhTT4/RLwMWB3oB0YXVTmXKDF06cBi+ptdx19MRHo7+lzdmVfeLlBwEpgFTCh3nbX8XtxELAWGOrrH6m33XX0xQ3AOZ4eDWyst91V8sVxwHhgfRfbpwAPkt5hOwJYnafeRu1RVEX+o5dS0RdmttzM3vXVVaR3VpqRPN8LgMuAnwD/rqVxNSaPL84GrjGzNwHMbHONbawVeXxhQEHvZzDbv9PVFJjZSsq/i3YScIslVgFDJA2vVG+jNhSl5D/27aqMmW0FCvIfzUYeX2Q5i/TE0IxU9IWkw4D9zOz+WhpWB/J8L0YBoyQ9KmmVpM/VzLrakscXc4EzJL0CLAHOr41pDUd37ydA485HsdPkP5qA3Ocp6QxgAnB8VS2qH2V9IWk3kgrxrFoZVEfyfC8+RAo/nUDqZT4iaYyZ/aPKttWaPL74ErDQzH4q6UjS+1tjzOx/1TevoejRfbNRexQh/9FJHl8gaRIwB5hqZv+pkW21ppIvBgFjgBWSNpJisK1NOqCd9zfyWzP7r5n9GXie1HA0G3l8cRZwF4CZPQ70IwkG7mrkup8U06gNRch/dFLRFx5uuZ7USDRrHBoq+MLM3jKzYWY2wsxGkMZrpppZj8XQGpg8v5HFpD86IGkYKRT1p5paWRvy+OJl4LMAkj5Baih2xXl7W4EZ/u+nI4C3zOzVSjs1ZOjJqif/0evI6Yt5wEDgbh/Pf9nMptbN6CqR0xe7BDl9sRSYLGkD8D7wHTPbUj+rq0NOX3wbuFHSbFKoZVYzPlhKuoMUahzm4zE/APoCmFkLaXxmCvAi8C5wZq56m9BXQRAEwU6kUUNPQRAEQYMQDUUQBEFQlmgogiAIgrJEQxEEQRCUJRqKIAiCoCzRUAQVFScz5ea4CmmHpDZJn97JdiyRNMTTF0h6VtJtkqaWU4r18o/55whJX+7BsQ+TtMDTsyS97ufYJumWCvvOlXRRd49ZVMcISe/58TZIavE3zbtbzxJJQ3w5N5O/j6R7dsTGLuy8RVLfHPtUvCaS9pL0+x21Mdj5REMRACwEyuoAuezBicB4MxsLTGJbzZgdxsymZOQlzgWmmNnpZtZqZldU2PcoT44Aut1QAN8DfplZX2Rm43yZ0YP6esJLZjYOGEtSOD25uxVkfDiE5MNC/iYzO3Un23ko6c3eaRXKjyDHNTGz14FXJR29wxYGO5VoKII8ipMAw4E3CvIgZvaGmW0CkLRR0pWSnvBlpOfvJeleSWt8OdrzB0q6WdI6752ckqlnmKQWkmR0q6TZ/oQ/38vsLek+Se2+HOX577idVwDH+hPvbEmPSBpXOAklgbyx2ROTNAgYa2bt5Rwg6Ww/j3Y/r/4lylygzrlB7vS8Ad5rW6M0H0IpxdsPcJHLx4CR/gbtPEnr3V/Tvc7hklb6ea6XdGzWh+6HA337PH+qX+9lVks6JGPzCkmH98DO94EncFE5P8Yjkp72pdB4F1+TPm7TGvfT1zPVLgZOL3fcoA7USzc9lsZaSE99JTXsfftAoA14AbgWOD6zbSMwx9MzgPs9fTtwjKf3B5719JXAVZn9h2bqGVYiPQuY7+lFwDc93QcY7Ol3/POEwvF9fWbhWCQJiydLnNtE4N7M+iySvEObL2d6/oczZS4Hzvf0XOAiT28C9vD0EP/8MXBGIc99OKAr/wP9SbIUnwdOAZb5ue5NkqIYTnrTeE7GD4Oyfiu+nkX1zwZ+6OnhwAs9tLMfsJzUyBbs7ufpgwq+LnFNvgZ839N7AE8CB/j6vsC6ev8eYtl2iR5FkAszewc4nPQjfx1YJGlWpsgdmc8jPT0JmC+pjaQxs6c/vU8CrsnU/WY3TPkMcJ3v976ZvVWh/N3AiR5H/yopzFbMcLbX/cmGnm72vDH+xLyO9NR7CNvTAdympOS71fMmA5e4H1aQbrD7l9j3QC/zKPCAmT0IHAPc4ef6GvBH4FOkhuRMSXOBQ83s7Qp+yHIX8EVPTyP5qCd2biHJxXR4fl+STMY6r3N0F8efTNIbagNWk6YHKIgVbgb26ca5BDWgIbWegvojaT/gd77aYmYtlkINK0jqrOtIT+sLvUxWC6aQ3g040szeK6pb1EgS3szelbSMNGHLNJIMezHvkW6KlVgInGxm7d5InlCizBdIs4xNBS71EI+AU8zs+Qr1F2L/WUpOxmVmKyUd58e7VdI8Mys76J7Z92+StngIbjpQCP10y06lCW9WSJpqSU9pNvAa8EnSte9q4iiRemNLS2zrR7oeQQMRPYqgJGb218wTdYukgyVlJarHAX/JrE/PfD7u6T8A5xUKZMYKivOHdsO0h0jTveKx7j2Ltr9NkhvPsgC4GlhjZqXGYp4FRuY49iDSYGtfSsTRlf6ltJ+ZLQcuJoVvBpLE6s73BrKg9puXlcB0P9e9SI3QE0rzom82sxtJApnFcx+X8kOWO93GwWa2zvO6Zacl1dFLgO961mDgVUtzPHyFFBIrZctS4Bz3I5JGSRrg20YBZf99F9SeaCiCguLk48DBkl6RdFaJYgOBXxcGaklhhbmZ7XtIWg1cSHqyBLgAmOADlhuAb3j+5cBQH4Rtx6Wwc3IhMNF7NE+xffinA9jqA86zAczsKeCfwM2UwMyeAwZ7WKwcl5JCJcuA50ps7wP8xm1bC/zc0j+QLiOFZTp8QPmyyqf5Aff5ObUDDwMXm9nfSb2ZNklrSeMYvyg6py3Ao+7jeSXqvYekuHxXJq8ndi4G+vtg+rXATEmrSDf8f3mZ4muyANgAPO3HuZ7O6MZE4IEcxw1qSKjHBjuM0iRBE8zsjXrbUgpJ+5BCZh+3LmY08xvY22a2oJa2BdsiaSVwUjfHrYIqEz2KoKmRNIPUC5jTVSPhXAc068yAvQIPrf0sGonGI3oUQRAEQVmiRxEEQRCUJRqKIAiCoCzRUARBEARliYYiCIIgKEs0FEEQBEFZ/g+RaPxikjTtdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Add the models to the list that you want to view on the ROC plot\n",
    "models = [\n",
    "{\n",
    "    'label': 'Logistic Regression',\n",
    "    'model': LogisticRegression(class_weight='balanced'),\n",
    "},\n",
    "{\n",
    "    'label': 'XGBoost Classifier',\n",
    "    'model': XGBClassifier(max_depth=10, n_estimators=300),\n",
    "}\n",
    "]\n",
    "\n",
    "# Below for loop iterates through your models list\n",
    "for m in models:\n",
    "    model = m['model'] # select the model\n",
    "    model.fit(X_train, y_train) # train the model\n",
    "    y_pred=model.predict(X_test) # predict the test data\n",
    "# Compute False postive rate, and True positive rate\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "# Calculate Area under the curve to display on the plot\n",
    "    auc = roc_auc_score(y_test,model.predict(X_test))\n",
    "# Now, plot the computed values\n",
    "    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (m['label'], auc))\n",
    "# Custom settings for the plot \n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.title('Logistic Regression v. XGBoost ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)\n",
      "  Starting server from C:\\Users\\Lester\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\Lester\\AppData\\Local\\Temp\\tmpekqanxd6\n",
      "  JVM stdout: C:\\Users\\Lester\\AppData\\Local\\Temp\\tmpekqanxd6\\h2o_Lester_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\Lester\\AppData\\Local\\Temp\\tmpekqanxd6\\h2o_Lester_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>18 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_Lester_ia9k7s</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>2.488 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         04 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.3\n",
       "H2O cluster version age:    18 days\n",
       "H2O cluster name:           H2O_from_python_Lester_ia9k7s\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    2.488 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.7.3 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# starting up h20\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%\n"
     ]
    }
   ],
   "source": [
    "# Training phase set up\n",
    "data = h2o.H2OFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up features and output for h2o models\n",
    "data['target'] = data['target'].asfactor()\n",
    "y = \"target\"\n",
    "cont_names = cont_names.tolist()\n",
    "x = cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%\n"
     ]
    }
   ],
   "source": [
    "# Setting up max time of model training\n",
    "aml = H2OAutoML(max_runtime_secs= 3600, max_models=60, sort_metric='AUC')\n",
    "aml.train(x = x, y = y, training_frame = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_23         </td><td style=\"text-align: right;\">0.899137</td><td style=\"text-align: right;\">0.0725193</td><td style=\"text-align: right;\">              0.310849</td><td style=\"text-align: right;\">0.132298</td><td style=\"text-align: right;\">0.0175027</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_18         </td><td style=\"text-align: right;\">0.897865</td><td style=\"text-align: right;\">0.0772037</td><td style=\"text-align: right;\">              0.356301</td><td style=\"text-align: right;\">0.134703</td><td style=\"text-align: right;\">0.0181448</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_13         </td><td style=\"text-align: right;\">0.893198</td><td style=\"text-align: right;\">0.0747932</td><td style=\"text-align: right;\">              0.332219</td><td style=\"text-align: right;\">0.133125</td><td style=\"text-align: right;\">0.0177224</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190911_090503                       </td><td style=\"text-align: right;\">0.890508</td><td style=\"text-align: right;\">0.07836  </td><td style=\"text-align: right;\">              0.364404</td><td style=\"text-align: right;\">0.133299</td><td style=\"text-align: right;\">0.0177685</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190911_090503</td><td style=\"text-align: right;\">0.889572</td><td style=\"text-align: right;\">0.0780451</td><td style=\"text-align: right;\">              0.303576</td><td style=\"text-align: right;\">0.133848</td><td style=\"text-align: right;\">0.0179153</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190911_090503                       </td><td style=\"text-align: right;\">0.888856</td><td style=\"text-align: right;\">0.0765385</td><td style=\"text-align: right;\">              0.345903</td><td style=\"text-align: right;\">0.132528</td><td style=\"text-align: right;\">0.0175636</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190911_090503                       </td><td style=\"text-align: right;\">0.887013</td><td style=\"text-align: right;\">0.0799721</td><td style=\"text-align: right;\">              0.351007</td><td style=\"text-align: right;\">0.133711</td><td style=\"text-align: right;\">0.0178787</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190911_090503   </td><td style=\"text-align: right;\">0.885839</td><td style=\"text-align: right;\">0.0751823</td><td style=\"text-align: right;\">              0.327658</td><td style=\"text-align: right;\">0.130637</td><td style=\"text-align: right;\">0.017066 </td></tr>\n",
       "<tr><td>GBM_5_AutoML_20190911_090503                       </td><td style=\"text-align: right;\">0.883991</td><td style=\"text-align: right;\">0.0754682</td><td style=\"text-align: right;\">              0.320514</td><td style=\"text-align: right;\">0.133106</td><td style=\"text-align: right;\">0.0177171</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_19         </td><td style=\"text-align: right;\">0.88295 </td><td style=\"text-align: right;\">0.0820056</td><td style=\"text-align: right;\">              0.3283  </td><td style=\"text-align: right;\">0.137745</td><td style=\"text-align: right;\">0.0189736</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20190911_090503                       </td><td style=\"text-align: right;\">0.882451</td><td style=\"text-align: right;\">0.0854546</td><td style=\"text-align: right;\">              0.349541</td><td style=\"text-align: right;\">0.141896</td><td style=\"text-align: right;\">0.0201344</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_17         </td><td style=\"text-align: right;\">0.88043 </td><td style=\"text-align: right;\">0.0758304</td><td style=\"text-align: right;\">              0.351772</td><td style=\"text-align: right;\">0.133366</td><td style=\"text-align: right;\">0.0177866</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_6          </td><td style=\"text-align: right;\">0.878755</td><td style=\"text-align: right;\">0.0793258</td><td style=\"text-align: right;\">              0.369221</td><td style=\"text-align: right;\">0.135831</td><td style=\"text-align: right;\">0.01845  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_21         </td><td style=\"text-align: right;\">0.875855</td><td style=\"text-align: right;\">0.0880057</td><td style=\"text-align: right;\">              0.378343</td><td style=\"text-align: right;\">0.13941 </td><td style=\"text-align: right;\">0.0194351</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_5          </td><td style=\"text-align: right;\">0.869541</td><td style=\"text-align: right;\">0.0843388</td><td style=\"text-align: right;\">              0.379047</td><td style=\"text-align: right;\">0.138544</td><td style=\"text-align: right;\">0.0191943</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_12         </td><td style=\"text-align: right;\">0.863889</td><td style=\"text-align: right;\">0.0872119</td><td style=\"text-align: right;\">              0.385552</td><td style=\"text-align: right;\">0.138037</td><td style=\"text-align: right;\">0.0190541</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_4          </td><td style=\"text-align: right;\">0.85793 </td><td style=\"text-align: right;\">0.0858855</td><td style=\"text-align: right;\">              0.398248</td><td style=\"text-align: right;\">0.138799</td><td style=\"text-align: right;\">0.0192652</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_9          </td><td style=\"text-align: right;\">0.854066</td><td style=\"text-align: right;\">0.0837253</td><td style=\"text-align: right;\">              0.375473</td><td style=\"text-align: right;\">0.136928</td><td style=\"text-align: right;\">0.0187494</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20190911_090503                       </td><td style=\"text-align: right;\">0.849801</td><td style=\"text-align: right;\">0.12972  </td><td style=\"text-align: right;\">              0.320611</td><td style=\"text-align: right;\">0.136398</td><td style=\"text-align: right;\">0.0186044</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_20         </td><td style=\"text-align: right;\">0.845771</td><td style=\"text-align: right;\">0.132875 </td><td style=\"text-align: right;\">              0.331651</td><td style=\"text-align: right;\">0.144718</td><td style=\"text-align: right;\">0.0209434</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_24         </td><td style=\"text-align: right;\">0.844205</td><td style=\"text-align: right;\">0.112283 </td><td style=\"text-align: right;\">              0.327632</td><td style=\"text-align: right;\">0.158722</td><td style=\"text-align: right;\">0.0251928</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_1          </td><td style=\"text-align: right;\">0.842846</td><td style=\"text-align: right;\">0.0987403</td><td style=\"text-align: right;\">              0.387115</td><td style=\"text-align: right;\">0.141864</td><td style=\"text-align: right;\">0.0201253</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20190911_090503                       </td><td style=\"text-align: right;\">0.840593</td><td style=\"text-align: right;\">0.140858 </td><td style=\"text-align: right;\">              0.338823</td><td style=\"text-align: right;\">0.136656</td><td style=\"text-align: right;\">0.0186748</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190911_090503_model_1 </td><td style=\"text-align: right;\">0.837848</td><td style=\"text-align: right;\">0.099644 </td><td style=\"text-align: right;\">              0.364501</td><td style=\"text-align: right;\">0.136159</td><td style=\"text-align: right;\">0.0185392</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190911_090503_model_5 </td><td style=\"text-align: right;\">0.837732</td><td style=\"text-align: right;\">0.113023 </td><td style=\"text-align: right;\">              0.398662</td><td style=\"text-align: right;\">0.145015</td><td style=\"text-align: right;\">0.0210293</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_2          </td><td style=\"text-align: right;\">0.832713</td><td style=\"text-align: right;\">0.0992051</td><td style=\"text-align: right;\">              0.34326 </td><td style=\"text-align: right;\">0.14194 </td><td style=\"text-align: right;\">0.0201469</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_8          </td><td style=\"text-align: right;\">0.831644</td><td style=\"text-align: right;\">0.0989358</td><td style=\"text-align: right;\">              0.394005</td><td style=\"text-align: right;\">0.141895</td><td style=\"text-align: right;\">0.0201341</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_3          </td><td style=\"text-align: right;\">0.829264</td><td style=\"text-align: right;\">0.125399 </td><td style=\"text-align: right;\">              0.399557</td><td style=\"text-align: right;\">0.148764</td><td style=\"text-align: right;\">0.0221307</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190911_090503_model_4 </td><td style=\"text-align: right;\">0.826485</td><td style=\"text-align: right;\">0.091244 </td><td style=\"text-align: right;\">              0.385968</td><td style=\"text-align: right;\">0.137932</td><td style=\"text-align: right;\">0.0190253</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_10         </td><td style=\"text-align: right;\">0.812411</td><td style=\"text-align: right;\">0.0994287</td><td style=\"text-align: right;\">              0.38884 </td><td style=\"text-align: right;\">0.141974</td><td style=\"text-align: right;\">0.0201566</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190911_090503_model_8 </td><td style=\"text-align: right;\">0.811046</td><td style=\"text-align: right;\">0.0886588</td><td style=\"text-align: right;\">              0.401632</td><td style=\"text-align: right;\">0.139806</td><td style=\"text-align: right;\">0.0195458</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20190911_090503              </td><td style=\"text-align: right;\">0.806341</td><td style=\"text-align: right;\">0.0902895</td><td style=\"text-align: right;\">              0.390406</td><td style=\"text-align: right;\">0.141548</td><td style=\"text-align: right;\">0.0200357</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190911_090503_model_3 </td><td style=\"text-align: right;\">0.787758</td><td style=\"text-align: right;\">0.13609  </td><td style=\"text-align: right;\">              0.381917</td><td style=\"text-align: right;\">0.141572</td><td style=\"text-align: right;\">0.0200426</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_26         </td><td style=\"text-align: right;\">0.780214</td><td style=\"text-align: right;\">0.129925 </td><td style=\"text-align: right;\">              0.381503</td><td style=\"text-align: right;\">0.153107</td><td style=\"text-align: right;\">0.0234416</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_15         </td><td style=\"text-align: right;\">0.775551</td><td style=\"text-align: right;\">0.205316 </td><td style=\"text-align: right;\">              0.379685</td><td style=\"text-align: right;\">0.161552</td><td style=\"text-align: right;\">0.026099 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_11         </td><td style=\"text-align: right;\">0.771562</td><td style=\"text-align: right;\">0.156831 </td><td style=\"text-align: right;\">              0.292359</td><td style=\"text-align: right;\">0.157227</td><td style=\"text-align: right;\">0.0247202</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190911_090503_model_2 </td><td style=\"text-align: right;\">0.766338</td><td style=\"text-align: right;\">0.192844 </td><td style=\"text-align: right;\">              0.383512</td><td style=\"text-align: right;\">0.145046</td><td style=\"text-align: right;\">0.0210383</td></tr>\n",
       "<tr><td>GLM_grid_1_AutoML_20190911_090503_model_1          </td><td style=\"text-align: right;\">0.763044</td><td style=\"text-align: right;\">0.0988381</td><td style=\"text-align: right;\">              0.337884</td><td style=\"text-align: right;\">0.142881</td><td style=\"text-align: right;\">0.0204151</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190911_090503_model_6 </td><td style=\"text-align: right;\">0.757693</td><td style=\"text-align: right;\">0.202875 </td><td style=\"text-align: right;\">              0.41701 </td><td style=\"text-align: right;\">0.143526</td><td style=\"text-align: right;\">0.0205998</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190911_090503_model_7 </td><td style=\"text-align: right;\">0.714082</td><td style=\"text-align: right;\">0.151606 </td><td style=\"text-align: right;\">              0.448678</td><td style=\"text-align: right;\">0.144808</td><td style=\"text-align: right;\">0.0209694</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_7          </td><td style=\"text-align: right;\">0.705055</td><td style=\"text-align: right;\">0.571222 </td><td style=\"text-align: right;\">              0.411615</td><td style=\"text-align: right;\">0.181179</td><td style=\"text-align: right;\">0.0328259</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_14         </td><td style=\"text-align: right;\">0.667582</td><td style=\"text-align: right;\">0.278682 </td><td style=\"text-align: right;\">              0.380391</td><td style=\"text-align: right;\">0.169044</td><td style=\"text-align: right;\">0.028576 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_16         </td><td style=\"text-align: right;\">0.630668</td><td style=\"text-align: right;\">0.785723 </td><td style=\"text-align: right;\">              0.383518</td><td style=\"text-align: right;\">0.205523</td><td style=\"text-align: right;\">0.0422397</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_25         </td><td style=\"text-align: right;\">0.606555</td><td style=\"text-align: right;\">1.66889  </td><td style=\"text-align: right;\">              0.399822</td><td style=\"text-align: right;\">0.255916</td><td style=\"text-align: right;\">0.0654932</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190911_090503_model_22         </td><td style=\"text-align: right;\">0.533312</td><td style=\"text-align: right;\">1.66969  </td><td style=\"text-align: right;\">              0.407439</td><td style=\"text-align: right;\">0.2475  </td><td style=\"text-align: right;\">0.0612563</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying best models built\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%\n",
      "gbm prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%\n"
     ]
    }
   ],
   "source": [
    "# Creating Predictions of best model\n",
    "hf = h2o.H2OFrame(test)\n",
    "preds = aml.predict(hf)\n",
    "preds = preds.as_data_frame()\n",
    "preds['p_p0'] = np.exp(preds['p0'])\n",
    "preds['p_p1'] = np.exp(preds['p1'])\n",
    "preds['sm'] = preds['p_p1'] / (preds['p_p0'] + preds['p_p1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873866623745909"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC score of best model\n",
    "roc_auc_score(y_test, preds['sm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>47764.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.92</td>\n",
       "      <td>24.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>45.97333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               75.0                      75.0              47764.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        8.0       14.0       13.92        24.0        62.0     45.97333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings of best model\n",
    "aml.leader.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\model_bankrupt\\\\GBM_grid_1_AutoML_20190911_090503_model_23'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving model for future use\n",
    "h2o.save_model(aml.leader, path = \"/model_bankrupt\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_1_AutoML_20190911_090503_model_23\n",
      "\n",
      "\n",
      "Model Summary: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>47764.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.92</td>\n",
       "      <td>24.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>45.97333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               75.0                      75.0              47764.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        8.0       14.0       13.92        24.0        62.0     45.97333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.008294580542420911\n",
      "RMSE: 0.0910745877971507\n",
      "LogLoss: 0.03230963368157359\n",
      "Mean Per-Class Error: 0.0061263560944480044\n",
      "AUC: 0.9991928216433641\n",
      "pr_auc: 0.9559313227273424\n",
      "Gini: 0.9983856432867282\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.18433657132730907: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7806.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>(29.0/7835.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>(6.0/165.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>7812.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>(35.0/8000.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1   Error            Rate\n",
       "0      0  7806.0   29.0  0.0037   (29.0/7835.0)\n",
       "1      1     6.0  159.0  0.0364     (6.0/165.0)\n",
       "2  Total  7812.0  188.0  0.0044   (35.0/8000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.184337</td>\n",
       "      <td>0.900850</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.176197</td>\n",
       "      <td>0.943728</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.234578</td>\n",
       "      <td>0.916775</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.234578</td>\n",
       "      <td>0.995750</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.779953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.779953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.184337</td>\n",
       "      <td>0.900623</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.134969</td>\n",
       "      <td>0.990938</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.993874</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        metric  threshold     value    idx\n",
       "0                       max f1   0.184337  0.900850  136.0\n",
       "1                       max f2   0.176197  0.943728  139.0\n",
       "2                 max f0point5   0.234578  0.916775  114.0\n",
       "3                 max accuracy   0.234578  0.995750  114.0\n",
       "4                max precision   0.779953  1.000000    0.0\n",
       "5                   max recall   0.111977  1.000000  173.0\n",
       "6              max specificity   0.779953  1.000000    0.0\n",
       "7             max absolute_mcc   0.184337  0.900623  136.0\n",
       "8   max min_per_class_accuracy   0.134969  0.990938  161.0\n",
       "9  max mean_per_class_accuracy   0.111977  0.993874  173.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  2.06 %, avg score:  2.08 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.410562</td>\n",
       "      <td>48.484848</td>\n",
       "      <td>48.484848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.563159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.563159</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>4748.484848</td>\n",
       "      <td>4748.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.218043</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>44.242424</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.309274</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.436216</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>3900.000000</td>\n",
       "      <td>4324.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.129953</td>\n",
       "      <td>10.909091</td>\n",
       "      <td>33.131313</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.169553</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.347329</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>990.909091</td>\n",
       "      <td>3213.131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.086596</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.286350</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-39.393939</td>\n",
       "      <td>2400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.072747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079353</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.244951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.038202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.051786</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.024680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.030497</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.109078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>566.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.017070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.086963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.062160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>233.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.051562</td>\n",
       "      <td>0.048428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.041250</td>\n",
       "      <td>0.039696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.029464</td>\n",
       "      <td>0.029162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.025781</td>\n",
       "      <td>0.025738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>0.023027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.020625</td>\n",
       "      <td>0.020826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0         1                      0.01         0.410562  48.484848   \n",
       "1         2                      0.02         0.218043  40.000000   \n",
       "2         3                      0.03         0.129953  10.909091   \n",
       "3         4                      0.04         0.086596   0.606061   \n",
       "4         5                      0.05         0.072747   0.000000   \n",
       "5         6                      0.10         0.038202   0.000000   \n",
       "6         7                      0.15         0.024680   0.000000   \n",
       "7         8                      0.20         0.017070   0.000000   \n",
       "8         9                      0.30         0.009097   0.000000   \n",
       "9        10                      0.40         0.005782   0.000000   \n",
       "10       11                      0.50         0.003889   0.000000   \n",
       "11       12                      0.60         0.002773   0.000000   \n",
       "12       13                      0.70         0.002037   0.000000   \n",
       "13       14                      0.80         0.001523   0.000000   \n",
       "14       15                      0.90         0.001163   0.000000   \n",
       "15       16                      1.00         0.000739   0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         48.484848         1.0000  0.563159                  1.000000   \n",
       "1         44.242424         0.8250  0.309274                  0.912500   \n",
       "2         33.131313         0.2250  0.169553                  0.683333   \n",
       "3         25.000000         0.0125  0.103414                  0.515625   \n",
       "4         20.000000         0.0000  0.079353                  0.412500   \n",
       "5         10.000000         0.0000  0.051786                  0.206250   \n",
       "6          6.666667         0.0000  0.030497                  0.137500   \n",
       "7          5.000000         0.0000  0.020620                  0.103125   \n",
       "8          3.333333         0.0000  0.012552                  0.068750   \n",
       "9          2.500000         0.0000  0.007233                  0.051562   \n",
       "10         2.000000         0.0000  0.004765                  0.041250   \n",
       "11         1.666667         0.0000  0.003280                  0.034375   \n",
       "12         1.428571         0.0000  0.002376                  0.029464   \n",
       "13         1.250000         0.0000  0.001774                  0.025781   \n",
       "14         1.111111         0.0000  0.001334                  0.022917   \n",
       "15         1.000000         0.0000  0.001017                  0.020625   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n",
       "0           0.563159      0.484848                 0.484848  4748.484848   \n",
       "1           0.436216      0.400000                 0.884848  3900.000000   \n",
       "2           0.347329      0.109091                 0.993939   990.909091   \n",
       "3           0.286350      0.006061                 1.000000   -39.393939   \n",
       "4           0.244951      0.000000                 1.000000  -100.000000   \n",
       "5           0.148368      0.000000                 1.000000  -100.000000   \n",
       "6           0.109078      0.000000                 1.000000  -100.000000   \n",
       "7           0.086963      0.000000                 1.000000  -100.000000   \n",
       "8           0.062160      0.000000                 1.000000  -100.000000   \n",
       "9           0.048428      0.000000                 1.000000  -100.000000   \n",
       "10          0.039696      0.000000                 1.000000  -100.000000   \n",
       "11          0.033626      0.000000                 1.000000  -100.000000   \n",
       "12          0.029162      0.000000                 1.000000  -100.000000   \n",
       "13          0.025738      0.000000                 1.000000  -100.000000   \n",
       "14          0.023027      0.000000                 1.000000  -100.000000   \n",
       "15          0.020826      0.000000                 1.000000  -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0       4748.484848  \n",
       "1       4324.242424  \n",
       "2       3213.131313  \n",
       "3       2400.000000  \n",
       "4       1900.000000  \n",
       "5        900.000000  \n",
       "6        566.666667  \n",
       "7        400.000000  \n",
       "8        233.333333  \n",
       "9        150.000000  \n",
       "10       100.000000  \n",
       "11        66.666667  \n",
       "12        42.857143  \n",
       "13        25.000000  \n",
       "14        11.111111  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.017502659944112167\n",
      "RMSE: 0.132297618814974\n",
      "LogLoss: 0.07251934003016451\n",
      "Mean Per-Class Error: 0.17694301019125525\n",
      "AUC: 0.899137127497051\n",
      "pr_auc: 0.25699470269712416\n",
      "Gini: 0.798274254994102\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1234223270831083: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>(170.0/7835.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>(99.0/165.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>7764.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>(269.0/8000.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1   Error             Rate\n",
       "0      0  7665.0  170.0  0.0217   (170.0/7835.0)\n",
       "1      1    99.0   66.0     0.6     (99.0/165.0)\n",
       "2  Total  7764.0  236.0  0.0336   (269.0/8000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.123422</td>\n",
       "      <td>0.329177</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.081283</td>\n",
       "      <td>0.383877</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.226554</td>\n",
       "      <td>0.365112</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.407422</td>\n",
       "      <td>0.980500</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.614278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.614278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.123422</td>\n",
       "      <td>0.317762</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>0.811359</td>\n",
       "      <td>296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.013511</td>\n",
       "      <td>0.823057</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        metric  threshold     value    idx\n",
       "0                       max f1   0.123422  0.329177  122.0\n",
       "1                       max f2   0.081283  0.383877  164.0\n",
       "2                 max f0point5   0.226554  0.365112   61.0\n",
       "3                 max accuracy   0.407422  0.980500   14.0\n",
       "4                max precision   0.614278  1.000000    0.0\n",
       "5                   max recall   0.002363  1.000000  380.0\n",
       "6              max specificity   0.614278  1.000000    0.0\n",
       "7             max absolute_mcc   0.123422  0.317762  122.0\n",
       "8   max min_per_class_accuracy   0.017966  0.811359  296.0\n",
       "9  max mean_per_class_accuracy   0.013511  0.823057  314.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  2.06 %, avg score:  1.75 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.227189</td>\n",
       "      <td>20.606061</td>\n",
       "      <td>20.606061</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.321355</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.321355</td>\n",
       "      <td>0.206061</td>\n",
       "      <td>0.206061</td>\n",
       "      <td>1960.606061</td>\n",
       "      <td>1960.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.151067</td>\n",
       "      <td>9.696970</td>\n",
       "      <td>15.151515</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.179055</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.250205</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>869.696970</td>\n",
       "      <td>1415.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.121095</td>\n",
       "      <td>9.696970</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.135438</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.211949</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>869.696970</td>\n",
       "      <td>1233.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.093698</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>11.212121</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.106015</td>\n",
       "      <td>0.231250</td>\n",
       "      <td>0.185466</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.448485</td>\n",
       "      <td>384.848485</td>\n",
       "      <td>1021.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.078557</td>\n",
       "      <td>4.242424</td>\n",
       "      <td>9.818182</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.085660</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>0.165505</td>\n",
       "      <td>0.042424</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>324.242424</td>\n",
       "      <td>881.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.042097</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.057357</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.111431</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>154.545455</td>\n",
       "      <td>518.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.026508</td>\n",
       "      <td>1.575758</td>\n",
       "      <td>4.646465</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.033601</td>\n",
       "      <td>0.095833</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>0.078788</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>57.575758</td>\n",
       "      <td>364.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.017996</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>4.030303</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>0.083125</td>\n",
       "      <td>0.069592</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>118.181818</td>\n",
       "      <td>303.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>3.050505</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>0.062917</td>\n",
       "      <td>0.050827</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.915152</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>205.050505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>2.409091</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.007725</td>\n",
       "      <td>0.049688</td>\n",
       "      <td>0.040052</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>-51.515152</td>\n",
       "      <td>140.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>1.975758</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.040750</td>\n",
       "      <td>0.033015</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>-75.757576</td>\n",
       "      <td>97.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.646465</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.033958</td>\n",
       "      <td>0.028066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>64.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.029464</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-87.878788</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.025781</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.020625</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0         1                      0.01         0.227189  20.606061   \n",
       "1         2                      0.02         0.151067   9.696970   \n",
       "2         3                      0.03         0.121095   9.696970   \n",
       "3         4                      0.04         0.093698   4.848485   \n",
       "4         5                      0.05         0.078557   4.242424   \n",
       "5         6                      0.10         0.042097   2.545455   \n",
       "6         7                      0.15         0.026508   1.575758   \n",
       "7         8                      0.20         0.017996   2.181818   \n",
       "8         9                      0.30         0.009917   1.090909   \n",
       "9        10                      0.40         0.006005   0.484848   \n",
       "10       11                      0.50         0.003942   0.242424   \n",
       "11       12                      0.60         0.002795   0.000000   \n",
       "12       13                      0.70         0.001997   0.121212   \n",
       "13       14                      0.80         0.001474   0.000000   \n",
       "14       15                      0.90         0.001118   0.000000   \n",
       "15       16                      1.00         0.000544   0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         20.606061         0.4250  0.321355                  0.425000   \n",
       "1         15.151515         0.2000  0.179055                  0.312500   \n",
       "2         13.333333         0.2000  0.135438                  0.275000   \n",
       "3         11.212121         0.1000  0.106015                  0.231250   \n",
       "4          9.818182         0.0875  0.085660                  0.202500   \n",
       "5          6.181818         0.0525  0.057357                  0.127500   \n",
       "6          4.646465         0.0325  0.033601                  0.095833   \n",
       "7          4.030303         0.0450  0.021907                  0.083125   \n",
       "8          3.050505         0.0225  0.013298                  0.062917   \n",
       "9          2.409091         0.0100  0.007725                  0.049688   \n",
       "10         1.975758         0.0050  0.004869                  0.040750   \n",
       "11         1.646465         0.0000  0.003320                  0.033958   \n",
       "12         1.428571         0.0025  0.002362                  0.029464   \n",
       "13         1.250000         0.0000  0.001720                  0.025781   \n",
       "14         1.111111         0.0000  0.001279                  0.022917   \n",
       "15         1.000000         0.0000  0.000921                  0.020625   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n",
       "0           0.321355      0.206061                 0.206061  1960.606061   \n",
       "1           0.250205      0.096970                 0.303030   869.696970   \n",
       "2           0.211949      0.096970                 0.400000   869.696970   \n",
       "3           0.185466      0.048485                 0.448485   384.848485   \n",
       "4           0.165505      0.042424                 0.490909   324.242424   \n",
       "5           0.111431      0.127273                 0.618182   154.545455   \n",
       "6           0.085488      0.078788                 0.696970    57.575758   \n",
       "7           0.069592      0.109091                 0.806061   118.181818   \n",
       "8           0.050827      0.109091                 0.915152     9.090909   \n",
       "9           0.040052      0.048485                 0.963636   -51.515152   \n",
       "10          0.033015      0.024242                 0.987879   -75.757576   \n",
       "11          0.028066      0.000000                 0.987879  -100.000000   \n",
       "12          0.024394      0.012121                 1.000000   -87.878788   \n",
       "13          0.021560      0.000000                 1.000000  -100.000000   \n",
       "14          0.019306      0.000000                 1.000000  -100.000000   \n",
       "15          0.017468      0.000000                 1.000000  -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0       1960.606061  \n",
       "1       1415.151515  \n",
       "2       1233.333333  \n",
       "3       1021.212121  \n",
       "4        881.818182  \n",
       "5        518.181818  \n",
       "6        364.646465  \n",
       "7        303.030303  \n",
       "8        205.050505  \n",
       "9        140.909091  \n",
       "10        97.575758  \n",
       "11        64.646465  \n",
       "12        42.857143  \n",
       "13        25.000000  \n",
       "14        11.111111  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.968375</td>\n",
       "      <td>0.007687754</td>\n",
       "      <td>0.960625</td>\n",
       "      <td>0.973125</td>\n",
       "      <td>0.979375</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.96375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.90159273</td>\n",
       "      <td>0.018951938</td>\n",
       "      <td>0.9015701</td>\n",
       "      <td>0.90902066</td>\n",
       "      <td>0.8715941</td>\n",
       "      <td>0.9022505</td>\n",
       "      <td>0.92352843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>err</td>\n",
       "      <td>0.031625</td>\n",
       "      <td>0.007687754</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>0.020625</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.03625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err_count</td>\n",
       "      <td>50.6</td>\n",
       "      <td>12.300406</td>\n",
       "      <td>63.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.3389019</td>\n",
       "      <td>0.07267198</td>\n",
       "      <td>0.28089887</td>\n",
       "      <td>0.38690478</td>\n",
       "      <td>0.44247788</td>\n",
       "      <td>0.3053435</td>\n",
       "      <td>0.27888447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.3531937</td>\n",
       "      <td>0.027158745</td>\n",
       "      <td>0.32258064</td>\n",
       "      <td>0.3768116</td>\n",
       "      <td>0.3773585</td>\n",
       "      <td>0.36363637</td>\n",
       "      <td>0.3255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.3830933</td>\n",
       "      <td>0.04378084</td>\n",
       "      <td>0.37878788</td>\n",
       "      <td>0.36723164</td>\n",
       "      <td>0.32894737</td>\n",
       "      <td>0.4494382</td>\n",
       "      <td>0.39106146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>18.729553</td>\n",
       "      <td>1.329624</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.444445</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>16.666666</td>\n",
       "      <td>19.35484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.07251934</td>\n",
       "      <td>0.005552909</td>\n",
       "      <td>0.07623816</td>\n",
       "      <td>0.07651082</td>\n",
       "      <td>0.07695944</td>\n",
       "      <td>0.06659759</td>\n",
       "      <td>0.06629069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.5844682</td>\n",
       "      <td>0.08798761</td>\n",
       "      <td>0.5714286</td>\n",
       "      <td>0.6388889</td>\n",
       "      <td>0.6969697</td>\n",
       "      <td>0.46666667</td>\n",
       "      <td>0.5483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.34927347</td>\n",
       "      <td>0.029374195</td>\n",
       "      <td>0.31389377</td>\n",
       "      <td>0.3634635</td>\n",
       "      <td>0.3794813</td>\n",
       "      <td>0.36762396</td>\n",
       "      <td>0.32190487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.6978131</td>\n",
       "      <td>0.039738595</td>\n",
       "      <td>0.7005477</td>\n",
       "      <td>0.6741617</td>\n",
       "      <td>0.6483244</td>\n",
       "      <td>0.7532909</td>\n",
       "      <td>0.7127408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.3021869</td>\n",
       "      <td>0.039738595</td>\n",
       "      <td>0.2994523</td>\n",
       "      <td>0.3258383</td>\n",
       "      <td>0.35167566</td>\n",
       "      <td>0.24670912</td>\n",
       "      <td>0.2872592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.01750266</td>\n",
       "      <td>0.0012049334</td>\n",
       "      <td>0.018696262</td>\n",
       "      <td>0.018641334</td>\n",
       "      <td>0.017643388</td>\n",
       "      <td>0.01620092</td>\n",
       "      <td>0.016331395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.3365935</td>\n",
       "      <td>0.10780791</td>\n",
       "      <td>0.25862068</td>\n",
       "      <td>0.3939394</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.27586207</td>\n",
       "      <td>0.25454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.13300978</td>\n",
       "      <td>0.013270105</td>\n",
       "      <td>0.12619933</td>\n",
       "      <td>0.15242584</td>\n",
       "      <td>0.12654807</td>\n",
       "      <td>0.11944045</td>\n",
       "      <td>0.14043519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.4155318</td>\n",
       "      <td>0.08798761</td>\n",
       "      <td>0.42857143</td>\n",
       "      <td>0.3611111</td>\n",
       "      <td>0.3030303</td>\n",
       "      <td>0.53333336</td>\n",
       "      <td>0.4516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.13223463</td>\n",
       "      <td>0.0045638275</td>\n",
       "      <td>0.13673428</td>\n",
       "      <td>0.13653328</td>\n",
       "      <td>0.13282841</td>\n",
       "      <td>0.12728283</td>\n",
       "      <td>0.12779436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>specificity</td>\n",
       "      <td>0.9800944</td>\n",
       "      <td>0.009701812</td>\n",
       "      <td>0.972524</td>\n",
       "      <td>0.9872123</td>\n",
       "      <td>0.99361837</td>\n",
       "      <td>0.9732484</td>\n",
       "      <td>0.9738687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean            sd   cv_1_valid  \\\n",
       "0                  accuracy    0.968375   0.007687754     0.960625   \n",
       "1                       auc  0.90159273   0.018951938    0.9015701   \n",
       "2                       err    0.031625   0.007687754     0.039375   \n",
       "3                 err_count        50.6     12.300406         63.0   \n",
       "4                  f0point5   0.3389019    0.07267198   0.28089887   \n",
       "5                        f1   0.3531937   0.027158745   0.32258064   \n",
       "6                        f2   0.3830933    0.04378084   0.37878788   \n",
       "7            lift_top_group   18.729553      1.329624         20.0   \n",
       "8                   logloss  0.07251934   0.005552909   0.07623816   \n",
       "9       max_per_class_error   0.5844682    0.08798761    0.5714286   \n",
       "10                      mcc  0.34927347   0.029374195   0.31389377   \n",
       "11  mean_per_class_accuracy   0.6978131   0.039738595    0.7005477   \n",
       "12     mean_per_class_error   0.3021869   0.039738595    0.2994523   \n",
       "13                      mse  0.01750266  0.0012049334  0.018696262   \n",
       "14                precision   0.3365935    0.10780791   0.25862068   \n",
       "15                       r2  0.13300978   0.013270105   0.12619933   \n",
       "16                   recall   0.4155318    0.08798761   0.42857143   \n",
       "17                     rmse  0.13223463  0.0045638275   0.13673428   \n",
       "18              specificity   0.9800944   0.009701812     0.972524   \n",
       "\n",
       "     cv_2_valid   cv_3_valid  cv_4_valid   cv_5_valid  \n",
       "0      0.973125     0.979375       0.965      0.96375  \n",
       "1    0.90902066    0.8715941   0.9022505   0.92352843  \n",
       "2      0.026875     0.020625       0.035      0.03625  \n",
       "3          43.0         33.0        56.0         58.0  \n",
       "4    0.38690478   0.44247788   0.3053435   0.27888447  \n",
       "5     0.3768116    0.3773585  0.36363637    0.3255814  \n",
       "6    0.36723164   0.32894737   0.4494382   0.39106146  \n",
       "7     19.444445    18.181818   16.666666     19.35484  \n",
       "8    0.07651082   0.07695944  0.06659759   0.06629069  \n",
       "9     0.6388889    0.6969697  0.46666667    0.5483871  \n",
       "10    0.3634635    0.3794813  0.36762396   0.32190487  \n",
       "11    0.6741617    0.6483244   0.7532909    0.7127408  \n",
       "12    0.3258383   0.35167566  0.24670912    0.2872592  \n",
       "13  0.018641334  0.017643388  0.01620092  0.016331395  \n",
       "14    0.3939394          0.5  0.27586207   0.25454545  \n",
       "15   0.15242584   0.12654807  0.11944045   0.14043519  \n",
       "16    0.3611111    0.3030303  0.53333336    0.4516129  \n",
       "17   0.13653328   0.13282841  0.12728283   0.12779436  \n",
       "18    0.9872123   0.99361837   0.9732484    0.9738687  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:05</td>\n",
       "      <td>4 min 58.709 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142125</td>\n",
       "      <td>0.100462</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:05</td>\n",
       "      <td>4 min 59.020 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.138810</td>\n",
       "      <td>0.085418</td>\n",
       "      <td>0.942869</td>\n",
       "      <td>0.254578</td>\n",
       "      <td>16.541889</td>\n",
       "      <td>0.052250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:05</td>\n",
       "      <td>4 min 59.363 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.135834</td>\n",
       "      <td>0.077219</td>\n",
       "      <td>0.956247</td>\n",
       "      <td>0.343420</td>\n",
       "      <td>23.636364</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:06</td>\n",
       "      <td>4 min 59.709 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.133102</td>\n",
       "      <td>0.071273</td>\n",
       "      <td>0.964590</td>\n",
       "      <td>0.405930</td>\n",
       "      <td>24.848485</td>\n",
       "      <td>0.026375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:06</td>\n",
       "      <td>5 min  0.037 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.129445</td>\n",
       "      <td>0.065383</td>\n",
       "      <td>0.975395</td>\n",
       "      <td>0.519861</td>\n",
       "      <td>32.727273</td>\n",
       "      <td>0.021250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:06</td>\n",
       "      <td>5 min  0.381 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.126039</td>\n",
       "      <td>0.060643</td>\n",
       "      <td>0.981740</td>\n",
       "      <td>0.582148</td>\n",
       "      <td>35.757576</td>\n",
       "      <td>0.017625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:07</td>\n",
       "      <td>5 min  0.709 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.122062</td>\n",
       "      <td>0.055967</td>\n",
       "      <td>0.987591</td>\n",
       "      <td>0.666364</td>\n",
       "      <td>38.787879</td>\n",
       "      <td>0.017750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:07</td>\n",
       "      <td>5 min  1.037 sec</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.118381</td>\n",
       "      <td>0.052237</td>\n",
       "      <td>0.990762</td>\n",
       "      <td>0.725246</td>\n",
       "      <td>40.606061</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:07</td>\n",
       "      <td>5 min  1.381 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.114403</td>\n",
       "      <td>0.048635</td>\n",
       "      <td>0.993502</td>\n",
       "      <td>0.781750</td>\n",
       "      <td>42.424242</td>\n",
       "      <td>0.011250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:08</td>\n",
       "      <td>5 min  1.711 sec</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.111327</td>\n",
       "      <td>0.045973</td>\n",
       "      <td>0.995124</td>\n",
       "      <td>0.819248</td>\n",
       "      <td>42.424242</td>\n",
       "      <td>0.010125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:08</td>\n",
       "      <td>5 min  2.038 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.107518</td>\n",
       "      <td>0.042981</td>\n",
       "      <td>0.996416</td>\n",
       "      <td>0.854376</td>\n",
       "      <td>43.636364</td>\n",
       "      <td>0.009250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:08</td>\n",
       "      <td>5 min  2.366 sec</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.104085</td>\n",
       "      <td>0.040522</td>\n",
       "      <td>0.997367</td>\n",
       "      <td>0.884839</td>\n",
       "      <td>44.848485</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:08</td>\n",
       "      <td>5 min  2.694 sec</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.101016</td>\n",
       "      <td>0.038387</td>\n",
       "      <td>0.997932</td>\n",
       "      <td>0.904017</td>\n",
       "      <td>46.060606</td>\n",
       "      <td>0.007750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:09</td>\n",
       "      <td>5 min  3.022 sec</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.097687</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>0.925216</td>\n",
       "      <td>47.272727</td>\n",
       "      <td>0.006125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:09</td>\n",
       "      <td>5 min  3.350 sec</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.094318</td>\n",
       "      <td>0.034151</td>\n",
       "      <td>0.998895</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>47.878788</td>\n",
       "      <td>0.005375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2019-09-11 09:12:09</td>\n",
       "      <td>5 min  3.684 sec</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.091075</td>\n",
       "      <td>0.032310</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>0.955931</td>\n",
       "      <td>48.484848</td>\n",
       "      <td>0.004375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp           duration  number_of_trees  training_rmse  \\\n",
       "0     2019-09-11 09:12:05   4 min 58.709 sec              0.0       0.142125   \n",
       "1     2019-09-11 09:12:05   4 min 59.020 sec              5.0       0.138810   \n",
       "2     2019-09-11 09:12:05   4 min 59.363 sec             10.0       0.135834   \n",
       "3     2019-09-11 09:12:06   4 min 59.709 sec             15.0       0.133102   \n",
       "4     2019-09-11 09:12:06   5 min  0.037 sec             20.0       0.129445   \n",
       "5     2019-09-11 09:12:06   5 min  0.381 sec             25.0       0.126039   \n",
       "6     2019-09-11 09:12:07   5 min  0.709 sec             30.0       0.122062   \n",
       "7     2019-09-11 09:12:07   5 min  1.037 sec             35.0       0.118381   \n",
       "8     2019-09-11 09:12:07   5 min  1.381 sec             40.0       0.114403   \n",
       "9     2019-09-11 09:12:08   5 min  1.711 sec             45.0       0.111327   \n",
       "10    2019-09-11 09:12:08   5 min  2.038 sec             50.0       0.107518   \n",
       "11    2019-09-11 09:12:08   5 min  2.366 sec             55.0       0.104085   \n",
       "12    2019-09-11 09:12:08   5 min  2.694 sec             60.0       0.101016   \n",
       "13    2019-09-11 09:12:09   5 min  3.022 sec             65.0       0.097687   \n",
       "14    2019-09-11 09:12:09   5 min  3.350 sec             70.0       0.094318   \n",
       "15    2019-09-11 09:12:09   5 min  3.684 sec             75.0       0.091075   \n",
       "\n",
       "    training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0           0.100462      0.500000         0.000000       1.000000   \n",
       "1           0.085418      0.942869         0.254578      16.541889   \n",
       "2           0.077219      0.956247         0.343420      23.636364   \n",
       "3           0.071273      0.964590         0.405930      24.848485   \n",
       "4           0.065383      0.975395         0.519861      32.727273   \n",
       "5           0.060643      0.981740         0.582148      35.757576   \n",
       "6           0.055967      0.987591         0.666364      38.787879   \n",
       "7           0.052237      0.990762         0.725246      40.606061   \n",
       "8           0.048635      0.993502         0.781750      42.424242   \n",
       "9           0.045973      0.995124         0.819248      42.424242   \n",
       "10          0.042981      0.996416         0.854376      43.636364   \n",
       "11          0.040522      0.997367         0.884839      44.848485   \n",
       "12          0.038387      0.997932         0.904017      46.060606   \n",
       "13          0.036218      0.998470         0.925216      47.272727   \n",
       "14          0.034151      0.998895         0.942500      47.878788   \n",
       "15          0.032310      0.999193         0.955931      48.484848   \n",
       "\n",
       "    training_classification_error  \n",
       "0                        0.979375  \n",
       "1                        0.052250  \n",
       "2                        0.029250  \n",
       "3                        0.026375  \n",
       "4                        0.021250  \n",
       "5                        0.017625  \n",
       "6                        0.017750  \n",
       "7                        0.012500  \n",
       "8                        0.011250  \n",
       "9                        0.010125  \n",
       "10                       0.009250  \n",
       "11                       0.008000  \n",
       "12                       0.007750  \n",
       "13                       0.006125  \n",
       "14                       0.005375  \n",
       "15                       0.004375  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attr34</td>\n",
       "      <td>47.270138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attr26</td>\n",
       "      <td>29.388826</td>\n",
       "      <td>0.621721</td>\n",
       "      <td>0.084878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attr29</td>\n",
       "      <td>21.753246</td>\n",
       "      <td>0.460190</td>\n",
       "      <td>0.062826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attr35</td>\n",
       "      <td>20.683378</td>\n",
       "      <td>0.437557</td>\n",
       "      <td>0.059736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Attr25</td>\n",
       "      <td>16.153364</td>\n",
       "      <td>0.341724</td>\n",
       "      <td>0.046653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Attr3</td>\n",
       "      <td>13.024249</td>\n",
       "      <td>0.275528</td>\n",
       "      <td>0.037615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Attr58</td>\n",
       "      <td>12.293855</td>\n",
       "      <td>0.260077</td>\n",
       "      <td>0.035506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Attr56</td>\n",
       "      <td>10.549563</td>\n",
       "      <td>0.223176</td>\n",
       "      <td>0.030468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Attr46</td>\n",
       "      <td>9.194869</td>\n",
       "      <td>0.194518</td>\n",
       "      <td>0.026556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Attr38</td>\n",
       "      <td>8.095933</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>0.023382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Attr48</td>\n",
       "      <td>8.018535</td>\n",
       "      <td>0.169632</td>\n",
       "      <td>0.023158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Attr2</td>\n",
       "      <td>7.077506</td>\n",
       "      <td>0.149725</td>\n",
       "      <td>0.020441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Attr11</td>\n",
       "      <td>7.070954</td>\n",
       "      <td>0.149586</td>\n",
       "      <td>0.020422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Attr24</td>\n",
       "      <td>6.807820</td>\n",
       "      <td>0.144019</td>\n",
       "      <td>0.019662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Attr51</td>\n",
       "      <td>6.524434</td>\n",
       "      <td>0.138024</td>\n",
       "      <td>0.018843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Attr20</td>\n",
       "      <td>6.329344</td>\n",
       "      <td>0.133897</td>\n",
       "      <td>0.018280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Attr9</td>\n",
       "      <td>6.142286</td>\n",
       "      <td>0.129940</td>\n",
       "      <td>0.017740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Attr22</td>\n",
       "      <td>6.133628</td>\n",
       "      <td>0.129757</td>\n",
       "      <td>0.017715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Attr32</td>\n",
       "      <td>5.666281</td>\n",
       "      <td>0.119870</td>\n",
       "      <td>0.016365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Attr16</td>\n",
       "      <td>5.436510</td>\n",
       "      <td>0.115009</td>\n",
       "      <td>0.015701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable  relative_importance  scaled_importance  percentage\n",
       "0    Attr34            47.270138           1.000000    0.136521\n",
       "1    Attr26            29.388826           0.621721    0.084878\n",
       "2    Attr29            21.753246           0.460190    0.062826\n",
       "3    Attr35            20.683378           0.437557    0.059736\n",
       "4    Attr25            16.153364           0.341724    0.046653\n",
       "5     Attr3            13.024249           0.275528    0.037615\n",
       "6    Attr58            12.293855           0.260077    0.035506\n",
       "7    Attr56            10.549563           0.223176    0.030468\n",
       "8    Attr46             9.194869           0.194518    0.026556\n",
       "9    Attr38             8.095933           0.171270    0.023382\n",
       "10   Attr48             8.018535           0.169632    0.023158\n",
       "11    Attr2             7.077506           0.149725    0.020441\n",
       "12   Attr11             7.070954           0.149586    0.020422\n",
       "13   Attr24             6.807820           0.144019    0.019662\n",
       "14   Attr51             6.524434           0.138024    0.018843\n",
       "15   Attr20             6.329344           0.133897    0.018280\n",
       "16    Attr9             6.142286           0.129940    0.017740\n",
       "17   Attr22             6.133628           0.129757    0.017715\n",
       "18   Attr32             5.666281           0.119870    0.016365\n",
       "19   Attr16             5.436510           0.115009    0.015701"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading model to avoid training time again\n",
    "saved_model = h2o.load_model('C:\\\\model_bankrupt\\\\GBM_grid_1_AutoML_20190911_090503_model_23')\n",
    "saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">        p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.992989</td><td style=\"text-align: right;\">0.00701058</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.830837</td><td style=\"text-align: right;\">0.169163  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.998767</td><td style=\"text-align: right;\">0.00123311</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.979724</td><td style=\"text-align: right;\">0.0202757 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.996949</td><td style=\"text-align: right;\">0.00305136</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.926129</td><td style=\"text-align: right;\">0.073871  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.998956</td><td style=\"text-align: right;\">0.00104367</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.95717 </td><td style=\"text-align: right;\">0.0428301 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.996181</td><td style=\"text-align: right;\">0.00381876</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.976387</td><td style=\"text-align: right;\">0.023613  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examlple on how to predict with loaded model\n",
    "saved_model.predict(hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p0 means % chance as prediction should be classified as a 0 (not bankrupt) v. p1 mean % chance as prediction shoulbe classified as a 1 (bankrupt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] in <ipython-input-27-d845937b4ee0> line 2:\n",
      "    >>> h2o.shutdown()\n",
      "        ^^^^ Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "H2O session _sid_879b closed.\n"
     ]
    }
   ],
   "source": [
    "# Closing an h2o session after use\n",
    "h2o.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
